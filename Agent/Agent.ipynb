{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9499ae21",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e424623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain==0.3.27\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core==0.3.79\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-openai==0.3.11\n",
      "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-community==0.3.31\n",
      "  Using cached langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langgraph==0.3.7\n",
      "  Downloading langgraph-0.3.7-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.7.21-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: yfinance==0.2.66 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (0.2.66)\n",
      "Collecting chromadb==1.3.4\n",
      "  Downloading chromadb-1.3.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Collecting pypdf==6.2.0\n",
      "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tiktoken==0.12.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (0.12.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain==0.3.27)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain==0.3.27) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain==0.3.27) (2.12.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain==0.3.27) (2.0.45)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain==0.3.27) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain==0.3.27) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain==0.3.27) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-core==0.3.79) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-core==0.3.79) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-core==0.3.79) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-core==0.3.79) (24.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-openai==0.3.11) (1.109.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from tiktoken==0.12.0) (2025.11.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-community==0.3.31) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-community==0.3.31) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-community==0.3.31) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-community==0.3.31) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langchain-community==0.3.31) (2.0.2)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.3.7)\n",
      "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph==0.3.7)\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.3.7)\n",
      "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (2.3.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (4.4.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (2.4.7)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (4.14.2)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (6.33.0)\n",
      "Requirement already satisfied: websockets>=13.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from yfinance==0.2.66) (15.0.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.4) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from chromadb==1.3.4) (4.25.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.31) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.3.31) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.3.31) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core==0.3.79) (3.0.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.7)\n",
      "  Downloading ormsgpack-1.11.0-cp39-cp39-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb==1.3.4) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb==1.3.4) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb==1.3.4) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb==1.3.4) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.3.4) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.11) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.11) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai==0.3.11) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb==1.3.4) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.3.4) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.3.4) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.3.4) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community==0.3.31) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain==0.3.27) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain==0.3.27) (2.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.3.31) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.66) (2.8)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb==1.3.4) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb==1.3.4) (8.7.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb==1.3.4) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from curl_cffi>=0.7->yfinance==0.2.66) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance==0.2.66) (2.23)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.6->build>=1.0.3->chromadb==1.3.4) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb==1.3.4) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb==1.3.4) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb==1.3.4) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb==1.3.4) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb==1.3.4) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb==1.3.4) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb==1.3.4) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.4) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.4) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.4) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.4) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb==1.3.4) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb==1.3.4) (25.9.23)\n",
      "Requirement already satisfied: sympy in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb==1.3.4) (1.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.4) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.4) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.4) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from opentelemetry-sdk>=1.2.0->chromadb==1.3.4) (0.60b1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from pandas>=1.3.0->yfinance==0.2.66) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb==1.3.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb==1.3.4) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.3.4) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from tokenizers>=0.13.2->chromadb==1.3.4) (0.36.0)\n",
      "Requirement already satisfied: filelock in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.3.4) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.3.4) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.3.4) (1.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb==1.3.4) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb==1.3.4) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.4) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.4) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.4) (1.1.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.3.4) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.3.4) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anshimittal/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==1.3.4) (1.3.0)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Downloading langchain_openai-0.3.11-py3-none-any.whl (60 kB)\n",
      "Using cached langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "Downloading langgraph-0.3.7-py3-none-any.whl (133 kB)\n",
      "Downloading chromadb-1.3.4-cp39-abi3-macosx_11_0_arm64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
      "Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Downloading tavily_python-0.7.21-py3-none-any.whl (17 kB)\n",
      "Downloading ormsgpack-1.11.0-cp39-cp39-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (367 kB)\n",
      "Installing collected packages: pypdf, ormsgpack, tavily-python, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, chromadb, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
      "\u001b[2K  Attempting uninstall: pypdf\n",
      "\u001b[2K    Found existing installation: pypdf 5.4.0\n",
      "\u001b[2K    Uninstalling pypdf-5.4.0:\n",
      "\u001b[2K      Successfully uninstalled pypdf-5.4.0\n",
      "\u001b[2K  Attempting uninstall: langchain-coreâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [langgraph-sdk]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.65â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [langgraph-sdk]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.65:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [langgraph-sdk]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.65â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [langgraph-sdk]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splittersâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.8[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.8:â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.8â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain-openaiâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-openai 0.3.24â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-openai-0.3.24:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-openai-0.3.24â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: chromadb90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: chromadb 0.6.3â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling chromadb-0.6.3:90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled chromadb-0.6.3m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [chromadb]e]\n",
      "\u001b[2K  Attempting uninstall: langchain[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [chromadb]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.25â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [chromadb]\n",
      "\u001b[2K    Uninstalling langchain-0.3.25:â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/13\u001b[0m [langchain]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.25m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/13\u001b[0m [langchain]\n",
      "\u001b[2K  Attempting uninstall: langchain-community0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [langgraph]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.3.20â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [langgraph]\n",
      "\u001b[2K    Uninstalling langchain-community-0.3.20:1mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [langgraph]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.3.20â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [langgraph]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/13\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed chromadb-1.3.4 langchain-0.3.27 langchain-community-0.3.31 langchain-core-0.3.79 langchain-openai-0.3.11 langchain-text-splitters-0.3.11 langgraph-0.3.7 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.74 ormsgpack-1.11.0 pypdf-6.2.0 tavily-python-0.7.21\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "âœ… All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Run this cell first before executing the rest of the notebook\n",
    "\n",
    "!pip install \\\n",
    "  langchain==0.3.27 \\\n",
    "  langchain-core==0.3.79 \\\n",
    "  langchain-openai==0.3.11 \\\n",
    "  langchain-community==0.3.31 \\\n",
    "  langgraph==0.3.7 \\\n",
    "  tavily-python \\\n",
    "  yfinance==0.2.66 \\\n",
    "  chromadb==1.3.4 \\\n",
    "  pypdf==6.2.0 \\\n",
    "  tiktoken==0.12.0\n",
    "\n",
    "print(\"âœ… All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50175d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, List, Literal\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "# External tools\n",
    "import yfinance as yf\n",
    "\n",
    "# Configure logging to see agent's decision-making process\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcef5d",
   "metadata": {},
   "source": [
    "Config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c03d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded successfully!\n",
      "   Using API base: https://aibe.mygreatlearning.com/openai/v1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load the JSON file and extract values\n",
    "file_name = 'config.json'\n",
    "with open(file_name, 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.get(\"API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = config.get(\"OPENAI_API_BASE\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = config.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "print(\"âœ… Configuration loaded successfully!\")\n",
    "print(f\"   Using API base: {os.environ['OPENAI_API_BASE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb236071",
   "metadata": {},
   "source": [
    "Traditional Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fef37fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Traditional LLM Prompt:\n",
      "================================================================================\n",
      "You are a helpful assistant.\n",
      "Answer the user's question about stock information.\n",
      "================================================================================\n",
      "\n",
      "âŒ Problems with this approach:\n",
      "   â€¢ No initiative - waits for user to specify what they want\n",
      "   â€¢ No comprehensive analysis - just answers the question\n",
      "   â€¢ Asks follow-up questions instead of taking action\n",
      "   â€¢ Provides minimal information\n"
     ]
    }
   ],
   "source": [
    "TRADITIONAL_PROMPT = \"\"\"You are a helpful assistant.\n",
    "Answer the user's question about stock information.\"\"\"\n",
    "\n",
    "print(\"ðŸ“‹ Traditional LLM Prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(TRADITIONAL_PROMPT)\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâŒ Problems with this approach:\")\n",
    "print(\"   â€¢ No initiative - waits for user to specify what they want\")\n",
    "print(\"   â€¢ No comprehensive analysis - just answers the question\")\n",
    "print(\"   â€¢ Asks follow-up questions instead of taking action\")\n",
    "print(\"   â€¢ Provides minimal information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f605154",
   "metadata": {},
   "source": [
    "Agent Charter Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab68c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Agent Charter (Goal-Oriented):\n",
      "================================================================================\n",
      "You are an autonomous Financial Research Analyst specializing in AI-focused companies.\n",
      "\n",
      "YOUR PRIMARY GOAL:\n",
      "Generate a comprehensive financial analysis report for the requested company that includes:\n",
      "1. Current stock price and 3-year performance trends\n",
      "2. Recent financial news and market sentiment\n",
      "3. Key risks and opportunities\n",
      "4. Investment recommendation with supporting evidence\n",
      "\n",
      "Take initiative to gather all necessary information to achieve this goal.\n",
      "Don't just answer questions - proactively provide complete, actionable insights.\n",
      "================================================================================\n",
      "\n",
      "âœ… Benefits of this approach:\n",
      "   â€¢ Defines a clear mission and goal\n",
      "   â€¢ Specifies expected output format\n",
      "   â€¢ Encourages proactive information gathering\n",
      "   â€¢ Focuses on actionable insights, not just answers\n"
     ]
    }
   ],
   "source": [
    "AGENT_CHARTER_BASIC = \"\"\"You are an autonomous Financial Research Analyst specializing in AI-focused companies.\n",
    "\n",
    "YOUR PRIMARY GOAL:\n",
    "Generate a comprehensive financial analysis report for the requested company that includes:\n",
    "1. Current stock price and 3-year performance trends\n",
    "2. Recent financial news and market sentiment\n",
    "3. Key risks and opportunities\n",
    "4. Investment recommendation with supporting evidence\n",
    "\n",
    "Take initiative to gather all necessary information to achieve this goal.\n",
    "Don't just answer questions - proactively provide complete, actionable insights.\"\"\"\n",
    "\n",
    "print(\"ðŸ“‹ Agent Charter (Goal-Oriented):\")\n",
    "print(\"=\"*80)\n",
    "print(AGENT_CHARTER_BASIC)\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… Benefits of this approach:\")\n",
    "print(\"   â€¢ Defines a clear mission and goal\")\n",
    "print(\"   â€¢ Specifies expected output format\")\n",
    "print(\"   â€¢ Encourages proactive information gathering\")\n",
    "print(\"   â€¢ Focuses on actionable insights, not just answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d0da7f",
   "metadata": {},
   "source": [
    "Tool 1: Stock Price Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923e0090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 1: get_stock_price() - Defined\n",
      "   Purpose: Fetch real-time stock price and basic metrics\n",
      "   Data Source: Yahoo Finance (yfinance)\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_stock_price(ticker: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns the current stock price and basic information for a given ticker symbol.\n",
    "\n",
    "    This tool fetches real-time stock data including current price, day's range,\n",
    "    volume, and market cap. Use this when you need current stock pricing information.\n",
    "\n",
    "    Args:\n",
    "        ticker: Stock ticker symbol (e.g., 'AAPL', 'MSFT', 'GOOGL')\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'ticker': str,\n",
    "            'current_price': float,\n",
    "            'currency': str,\n",
    "            'day_high': float,\n",
    "            'day_low': float,\n",
    "            'volume': int,\n",
    "            'market_cap': int,\n",
    "            'timestamp': str,\n",
    "            'status': str,\n",
    "            'error': str (optional)\n",
    "        }\n",
    "\n",
    "    Example:\n",
    "        >>> result = get_stock_price(\"AAPL\")\n",
    "        >>> print(f\"Apple stock price: ${result['current_price']}\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker.upper())\n",
    "        info = stock.info\n",
    "\n",
    "        # Get current price (try multiple fields as yfinance API can vary)\n",
    "        current_price = (\n",
    "            info.get('currentPrice') or\n",
    "            info.get('regularMarketPrice') or\n",
    "            info.get('previousClose')\n",
    "        )\n",
    "\n",
    "        if current_price is None:\n",
    "            return {\n",
    "                'ticker': ticker.upper(),\n",
    "                'status': 'error',\n",
    "                'error': f'Could not retrieve price data for {ticker}. Ticker may be invalid.'\n",
    "            }\n",
    "\n",
    "        result = {\n",
    "            'ticker': ticker.upper(),\n",
    "            'current_price': round(current_price, 2),\n",
    "            'currency': info.get('currency', 'USD'),\n",
    "            'day_high': info.get('dayHigh', info.get('regularMarketDayHigh')),\n",
    "            'day_low': info.get('dayLow', info.get('regularMarketDayLow')),\n",
    "            'volume': info.get('volume', info.get('regularMarketVolume')),\n",
    "            'market_cap': info.get('marketCap'),\n",
    "            'company_name': info.get('longName', info.get('shortName')),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'status': 'success'\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'ticker': ticker.upper(),\n",
    "            'status': 'error',\n",
    "            'error': f'Error fetching stock data: {str(e)}',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "print(\"âœ… Tool 1: get_stock_price() - Defined\")\n",
    "print(\"   Purpose: Fetch real-time stock price and basic metrics\")\n",
    "print(\"   Data Source: Yahoo Finance (yfinance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0cf57",
   "metadata": {},
   "source": [
    "Tool 2: Stock History Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479fb335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 2: get_stock_history() - Defined\n",
      "   Purpose: Fetch historical performance for trend analysis\n",
      "   Key Metric: 3-year return percentage\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def get_stock_history(ticker: str, period: str = \"1y\") -> Dict:\n",
    "    \"\"\"\n",
    "    Returns historical stock price data for analysis of 3-year performance.\n",
    "\n",
    "    This tool fetches historical stock data over a specified period, useful for\n",
    "    analyzing trends, calculating returns, and assessing long-term performance.\n",
    "\n",
    "    Args:\n",
    "        ticker: Stock ticker symbol (e.g., 'AAPL', 'MSFT', 'GOOGL')\n",
    "        period: Time period for historical data. Options: '1mo', '3mo', '6mo',\n",
    "                '1y', '2y', '3y', '5y', '10y'. Default is '1y'.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'ticker': str,\n",
    "            'period': str,\n",
    "            'start_date': str,\n",
    "            'end_date': str,\n",
    "            'start_price': float,\n",
    "            'end_price': float,\n",
    "            'return_pct': float,\n",
    "            'high': float,\n",
    "            'low': float,\n",
    "            'avg_volume': int,\n",
    "            'data_points': int,\n",
    "            'status': str\n",
    "        }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker.upper())\n",
    "        hist = stock.history(period=period)\n",
    "\n",
    "        if hist.empty:\n",
    "            return {\n",
    "                'ticker': ticker.upper(),\n",
    "                'status': 'error',\n",
    "                'error': f'No historical data available for {ticker} over period {period}'\n",
    "            }\n",
    "\n",
    "        # Calculate key metrics\n",
    "        start_price = hist['Close'].iloc[0]\n",
    "        end_price = hist['Close'].iloc[-1]\n",
    "        return_pct = ((end_price - start_price) / start_price) * 100\n",
    "\n",
    "        result = {\n",
    "            'ticker': ticker.upper(),\n",
    "            'period': period,\n",
    "            'start_date': hist.index[0].strftime('%Y-%m-%d'),\n",
    "            'end_date': hist.index[-1].strftime('%Y-%m-%d'),\n",
    "            'start_price': round(start_price, 2),\n",
    "            'end_price': round(end_price, 2),\n",
    "            'return_pct': round(return_pct, 2),\n",
    "            'high': round(hist['High'].max(), 2),\n",
    "            'low': round(hist['Low'].min(), 2),\n",
    "            'avg_volume': int(hist['Volume'].mean()),\n",
    "            'data_points': len(hist),\n",
    "            'status': 'success'\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'ticker': ticker.upper(),\n",
    "            'status': 'error',\n",
    "            'error': f'Error fetching historical data: {str(e)}'\n",
    "        }\n",
    "\n",
    "print(\"âœ… Tool 2: get_stock_history() - Defined\")\n",
    "print(\"   Purpose: Fetch historical performance for trend analysis\")\n",
    "print(\"   Key Metric: 3-year return percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8496651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 3: search_financial_news() - Defined\n",
      "   Purpose: Search real-time financial news\n",
      "   Data Source: Tavily Search API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/flyc_kxs2d554dt8_szth1_40000gn/T/ipykernel_9329/2699283982.py:4: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize Tavily search tool\n",
    "tavily_tool = TavilySearchResults(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=False,\n",
    "    include_images=False,\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search_financial_news(query: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Searches real-time financial news using Tavily search API.\n",
    "\n",
    "    This tool searches the web for recent financial news articles related to your query.\n",
    "    Use this to find market sentiment, recent developments, and news about companies.\n",
    "\n",
    "    Args:\n",
    "        query: Search query string (e.g., \"Apple AI initiatives 2024\")\n",
    "\n",
    "    Returns:\n",
    "        list: List of news articles with:\n",
    "            - title: Article title\n",
    "            - url: Article URL\n",
    "            - content: Article snippet/summary\n",
    "            - score: Relevance score\n",
    "\n",
    "    Example:\n",
    "        >>> results = search_financial_news(\"Microsoft AI research\")\n",
    "        >>> for article in results:\n",
    "        >>>     print(f\"{article['title']}: {article['url']}\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = tavily_tool.invoke({\"query\": query})\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return [{\n",
    "            'status': 'error',\n",
    "            'error': f'Error searching news: {str(e)}'\n",
    "        }]\n",
    "\n",
    "print(\"âœ… Tool 3: search_financial_news() - Defined\")\n",
    "print(\"   Purpose: Search real-time financial news\")\n",
    "print(\"   Data Source: Tavily Search API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf91102",
   "metadata": {},
   "source": [
    "Tool 3: Financial News Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35da05e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 4: analyze_sentiment() - Defined\n",
      "   Purpose: Analyze sentiment of financial text\n",
      "   Method: OpenAI gpt-4o-mini with keyword fallback\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def analyze_sentiment(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of financial text using OpenAI.\n",
    "\n",
    "    This tool analyzes the sentiment (positive/negative/neutral) of news articles,\n",
    "    reports, or any financial text. Returns a sentiment label and confidence score.\n",
    "\n",
    "    Args:\n",
    "        text: Text to analyze (article, headline, report excerpt)\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'sentiment': str ('positive', 'negative', or 'neutral'),\n",
    "            'score': float (0.0 to 1.0, where 1.0 is most positive),\n",
    "            'confidence': float (0.0 to 1.0),\n",
    "            'reasoning': str (brief explanation)\n",
    "        }\n",
    "\n",
    "    Example:\n",
    "        >>> result = analyze_sentiment(\"Apple reports record earnings...\")\n",
    "        >>> print(f\"Sentiment: {result['sentiment']} (score: {result['score']})\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        prompt = f\"\"\"Analyze the sentiment of this financial text and provide:\n",
    "1. Sentiment label: positive, negative, or neutral\n",
    "2. Score: 0.0 (very negative) to 1.0 (very positive), 0.5 is neutral\n",
    "3. Confidence: 0.0 to 1.0\n",
    "4. Brief reasoning\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "    \"sentiment\": \"positive|negative|neutral\",\n",
    "    \"score\": 0.0-1.0,\n",
    "    \"confidence\": 0.0-1.0,\n",
    "    \"reasoning\": \"brief explanation\"\n",
    "}}\"\"\"\n",
    "\n",
    "        response = model.invoke(prompt) # Ask the llm to predict the sentiment of the given text\n",
    "        result = json.loads(response.content)\n",
    "        result['status'] = 'success'\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fallback to simple sentiment if OpenAI fails\n",
    "        positive_words = ['growth', 'profit', 'gain', 'success', 'up', 'positive', 'strong']\n",
    "        negative_words = ['loss', 'decline', 'down', 'weak', 'risk', 'concern', 'negative']\n",
    "\n",
    "        text_lower = text.lower()\n",
    "        pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "        neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "\n",
    "        if pos_count > neg_count:\n",
    "            sentiment = 'positive'\n",
    "            score = 0.6 + (pos_count * 0.05)\n",
    "        elif neg_count > pos_count:\n",
    "            sentiment = 'negative'\n",
    "            score = 0.4 - (neg_count * 0.05)\n",
    "        else:\n",
    "            sentiment = 'neutral'\n",
    "            score = 0.5\n",
    "\n",
    "        return {\n",
    "            'sentiment': sentiment,\n",
    "            'score': max(0.0, min(1.0, score)),\n",
    "            'confidence': 0.6,\n",
    "            'reasoning': 'Fallback keyword-based analysis',\n",
    "            'status': 'success (fallback)',\n",
    "            'note': f'OpenAI analysis failed: {str(e)}'\n",
    "        }\n",
    "\n",
    "print(\"âœ… Tool 4: analyze_sentiment() - Defined\")\n",
    "print(\"   Purpose: Analyze sentiment of financial text\")\n",
    "print(\"   Method: OpenAI gpt-4o-mini with keyword fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff12ec",
   "metadata": {},
   "source": [
    "Tool 4: Sentiment Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83cfb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing get_stock_price tool with ticker 'AAPL':\n",
      "\n",
      "{\n",
      "  \"ticker\": \"AAPL\",\n",
      "  \"current_price\": 260.45,\n",
      "  \"currency\": \"USD\",\n",
      "  \"day_high\": 261.38,\n",
      "  \"day_low\": 255.54,\n",
      "  \"volume\": 16923985,\n",
      "  \"market_cap\": 3828148076544,\n",
      "  \"company_name\": \"Apple Inc.\",\n",
      "  \"timestamp\": \"2026-02-17T11:45:55.144613\",\n",
      "  \"status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ§ª Testing get_stock_history tool with ticker 'AAPL' and period '3y':\n",
      "\n",
      "{\n",
      "  \"ticker\": \"AAPL\",\n",
      "  \"period\": \"3y\",\n",
      "  \"start_date\": \"2023-02-17\",\n",
      "  \"end_date\": \"2026-02-17\",\n",
      "  \"start_price\": 150.37,\n",
      "  \"end_price\": 260.45,\n",
      "  \"return_pct\": 73.21,\n",
      "  \"high\": 288.35,\n",
      "  \"low\": 141.85,\n",
      "  \"avg_volume\": 55946451,\n",
      "  \"data_points\": 751,\n",
      "  \"status\": \"success\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test get_stock_price manually\n",
    "print(\"ðŸ§ª Testing get_stock_price tool with ticker 'AAPL':\\n\")\n",
    "result = get_stock_price(\"AAPL\")\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test get_stock_history manually\n",
    "print(\"ðŸ§ª Testing get_stock_history tool with ticker 'AAPL' and period '3y':\\n\")\n",
    "result = get_stock_history.invoke({\"ticker\": \"AAPL\", \"period\": \"3y\"})\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ed658",
   "metadata": {},
   "source": [
    "Full Agent Charter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26d8cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Full Agent Charter with Constraints:\n",
      "================================================================================\n",
      "Key features:\n",
      "âœ… Proactive Behavior: Takes initiative, gathers comprehensive data\n",
      "âœ… Reactive Behavior: Handles tool failures, adapts to missing data\n",
      "âœ… Autonomous Behavior: Makes independent judgments, cites sources\n",
      "âœ… Quality Standards: Structured output with confidence levels\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "AGENT_CHARTER_FULL = \"\"\"You are an autonomous Financial Research Analyst Agent specializing in AI sector investments.\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "PRIMARY MISSION\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Analyze public companies (especially AI-focused) to generate comprehensive, real-time\n",
    "investment research briefings that provide insights beyond simple data lookup.\n",
    "\n",
    "TARGET OUTPUT:\n",
    "A structured report covering:\n",
    "â€¢ Financial Health: Stock performance, 3-year trends, key metrics\n",
    "â€¢ Market Sentiment: News analysis with sentiment scores\n",
    "â€¢ AI Research Activity: Current AI projects and innovations\n",
    "â€¢ Risk Assessment: Key risks and opportunities\n",
    "â€¢ Investment Recommendation: Data-driven rating with confidence level\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "AVAILABLE TOOLS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Stock Data Tools:\n",
    "â€¢ get_stock_price(ticker) - Current price, volume, market cap\n",
    "â€¢ get_stock_history(ticker, period) - Historical data (use '3y' for 3-year analysis)\n",
    "\n",
    "News & Sentiment Tools:\n",
    "â€¢ search_financial_news(query) - Real-time financial news search\n",
    "â€¢ analyze_sentiment(text) - Sentiment analysis with score\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "PROACTIVE BEHAVIOR - Take Initiative\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "âœ“ ALWAYS gather comprehensive data, not just what's explicitly requested\n",
    "âœ“ ALWAYS check 3-year historical performance, not just current price\n",
    "âœ“ ALWAYS analyze recent news sentiment, even if not asked\n",
    "âœ“ ALWAYS identify risks proactively, don't wait to be asked\n",
    "âœ“ ALWAYS make a clear recommendation with confidence level\n",
    "\n",
    "âœ— NEVER stop at surface-level data\n",
    "âœ— NEVER provide analysis without supporting evidence\n",
    "âœ— NEVER ignore warning signs in the data\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "REACTIVE BEHAVIOR - Error Handling & Adaptability\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "When Tools Fail:\n",
    "â€¢ If a tool returns an error, IMMEDIATELY try an alternative approach\n",
    "â€¢ If stock data fails, explain the limitation and use news/company info instead\n",
    "â€¢ If news search fails, note this gap and continue with available data\n",
    "â€¢ NEVER stop your analysis due to a single tool failure\n",
    "â€¢ Log all errors but maintain momentum toward your goal\n",
    "\n",
    "When Data is Missing:\n",
    "â€¢ If you cannot get 3-year data, use whatever period is available and note it\n",
    "â€¢ If sentiment analysis fails, make qualitative assessment from news titles\n",
    "â€¢ If news is sparse, note this as a finding (low media coverage = risk/opportunity?)\n",
    "â€¢ ALWAYS work with what you have, document what you don't have\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "AUTONOMOUS BEHAVIOR - Independence & Judgment\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Data Gaps & Transparency:\n",
    "â€¢ If you encounter missing data, EXPLICITLY state the gap in your report\n",
    "â€¢ Explain the impact of missing data on your analysis confidence\n",
    "â€¢ NEVER pretend to have data you don't have\n",
    "\n",
    "Source Citation (MANDATORY):\n",
    "â€¢ You MUST cite the source for every factual claim\n",
    "â€¢ Include timestamps for time-sensitive data (stock prices, news)\n",
    "â€¢ Format: [Source: tool_name, timestamp]\n",
    "\n",
    "Example:\n",
    "âœ“ \"AAPL is trading at $178.45 [Source: get_stock_price, 2024-10-30 13:30]\"\n",
    "âœ“ \"Recent news shows positive sentiment (score: 0.75) [Source: analyze_sentiment]\"\n",
    "âœ— \"The stock is doing well\" (no source, no metrics)\n",
    "\n",
    "Confidence & Nuance:\n",
    "â€¢ Include confidence levels for predictions: High/Medium/Low\n",
    "â€¢ Acknowledge uncertainty: \"Data suggests...\" vs \"Data confirms...\"\n",
    "â€¢ Note when analysis is limited by data availability\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "QUALITY STANDARDS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Every Report Must Include:\n",
    "1. Executive Summary (2-3 sentences)\n",
    "2. Financial Metrics (with sources and timestamps)\n",
    "3. Sentiment Analysis (with scores and article count)\n",
    "4. Risk Factors (minimum 2-3 identified)\n",
    "5. AI Research Activity (verified presence/absence)\n",
    "6. Recommendation (Buy/Hold/Sell with confidence %)\n",
    "7. Source Citations (for all claims)\n",
    "8. Gaps & Limitations (what data was unavailable)\n",
    "\n",
    "Remember: You are AUTONOMOUS. Take initiative, handle errors gracefully, and\n",
    "always drive toward your goal of comprehensive investment analysis.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ðŸ“‹ Full Agent Charter with Constraints:\")\n",
    "print(\"=\"*80)\n",
    "print(\"Key features:\")\n",
    "print(\"âœ… Proactive Behavior: Takes initiative, gathers comprehensive data\")\n",
    "print(\"âœ… Reactive Behavior: Handles tool failures, adapts to missing data\")\n",
    "print(\"âœ… Autonomous Behavior: Makes independent judgments, cites sources\")\n",
    "print(\"âœ… Quality Standards: Structured output with confidence levels\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c97ba",
   "metadata": {},
   "source": [
    "Agent State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e443e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent state defined\n"
     ]
    }
   ],
   "source": [
    "class SimpleAgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    State for the financial research agent.\n",
    "    Tracks the conversation history with message accumulation.\n",
    "    \"\"\"\n",
    "    messages: Annotated[Sequence, add_messages]\n",
    "\n",
    "print(\"âœ… Agent state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e50eb",
   "metadata": {},
   "source": [
    "Agent Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89b61d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent creation function defined\n"
     ]
    }
   ],
   "source": [
    "def create_financial_agent(agent_type: str = \"full\", with_memory: bool = True):\n",
    "    \"\"\"\n",
    "    Creates a financial research agent with specified configuration.\n",
    "\n",
    "    Args:\n",
    "        agent_type: Type of agent to create:\n",
    "            - \"traditional\": Simple reactive LLM\n",
    "            - \"basic\": Basic goal-oriented agent\n",
    "            - \"full\": Full autonomous agent with all constraints\n",
    "        with_memory: Whether to enable conversation memory\n",
    "\n",
    "    Returns:\n",
    "        Compiled LangGraph agent\n",
    "    \"\"\"\n",
    "    # Select system prompt based on agent type\n",
    "    prompt_map = {\n",
    "        \"traditional\": TRADITIONAL_PROMPT,\n",
    "        \"basic\": AGENT_CHARTER_BASIC,\n",
    "        \"full\": AGENT_CHARTER_FULL\n",
    "    }\n",
    "\n",
    "    system_prompt = prompt_map.get(agent_type, AGENT_CHARTER_FULL)\n",
    "\n",
    "    # Collect all tools\n",
    "    tools = [ get_stock_price,\n",
    "    get_stock_history,\n",
    "    search_financial_news,\n",
    "    analyze_sentiment ]\n",
    "\n",
    "    logger.info(f\"ðŸ“¦ Creating {agent_type.upper()} agent with {len(tools)} tools\")\n",
    "    logger.info(f\"   Tools: {', '.join(t.name for t in tools)}\")\n",
    "\n",
    "    # Initialize model with tools\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    # Define agent node\n",
    "    def agent_node(state: SimpleAgentState) -> dict:\n",
    "        \"\"\"Agent node that calls the LLM with system prompt and current state.\"\"\"\n",
    "        logger.info(\"ðŸ¤– AGENT NODE: Processing request...\")\n",
    "\n",
    "        # Prepare messages with system prompt\n",
    "        system_msg = SystemMessage(content=system_prompt)\n",
    "        messages = [system_msg] + list(state[\"messages\"])\n",
    "\n",
    "        # Invoke model\n",
    "        logger.info(\"   Calling LLM with tools...\")\n",
    "        response = model_with_tools.invoke(messages)\n",
    "\n",
    "        # Log if agent wants to use tools\n",
    "        if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "            logger.info(f\"   âœ“ Agent decided to use {len(response.tool_calls)} tool(s)\")\n",
    "            for i, tool_call in enumerate(response.tool_calls, 1):\n",
    "                logger.info(f\"      {i}. {tool_call['name']}\")\n",
    "        else:\n",
    "            logger.info(\"   âœ“ Agent generated final response (no tools needed)\")\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # Define routing function\n",
    "    def should_continue(state: SimpleAgentState) -> Literal[\"tools\", \"end\"]:\n",
    "        \"\"\"Determines whether to continue to tools or end.\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            logger.info(\"ðŸ”€ ROUTING: Continuing to TOOLS node\")\n",
    "            return  \"tools\"\n",
    "\n",
    "        logger.info(\"ðŸ”€ ROUTING: Ending workflow (final response ready)\")\n",
    "        return  \"end\"\n",
    "    # Create workflow\n",
    "    workflow = StateGraph(SimpleAgentState)\n",
    "\n",
    "    # Create tool node with logging\n",
    "    original_tool_node = ToolNode(tools)\n",
    "\n",
    "    def tool_node_with_logging(state):\n",
    "        logger.info(\"ðŸ”§ TOOL NODE: Executing tools...\")\n",
    "        result = original_tool_node.invoke(state)\n",
    "        logger.info(f\"   âœ“ Tools executed successfully\")\n",
    "        return result\n",
    "\n",
    "    # Add nodes to graph\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", tool_node_with_logging)\n",
    "\n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "\n",
    "    # Add conditional edge from agent\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add edge from tools back to agent\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # Compile graph\n",
    "    if with_memory:\n",
    "        logger.info(\"ðŸ’¾ Enabling conversation memory\")\n",
    "        memory = MemorySaver()\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "    else:\n",
    "        logger.info(\"âš ï¸  Memory disabled - stateless mode\")\n",
    "        graph = workflow.compile()\n",
    "\n",
    "    logger.info(\"âœ… Agent created successfully\\n\")\n",
    "    return graph\n",
    "\n",
    "print(\"âœ… Agent creation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe08bc",
   "metadata": {},
   "source": [
    "Test 1: Traditional LLM Reactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880dace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:47 [INFO] ðŸ“¦ Creating TRADITIONAL agent with 4 tools\n",
      "12:28:47 [INFO]    Tools: get_stock_price, get_stock_history, search_financial_news, analyze_sentiment\n",
      "12:28:47 [INFO] âš ï¸  Memory disabled - stateless mode\n",
      "12:28:47 [INFO] âœ… Agent created successfully\n",
      "\n",
      "12:28:47 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "12:28:47 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: Traditional Reactive LLM\n",
      "================================================================================\n",
      "\n",
      "Query: Tell me about Apple stock\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:28:48 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12:28:48 [INFO]    âœ“ Agent decided to use 1 tool(s)\n",
      "12:28:48 [INFO]       1. get_stock_price\n",
      "12:28:48 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "12:28:48 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "12:28:48 [INFO]    âœ“ Tools executed successfully\n",
      "12:28:48 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "12:28:48 [INFO]    Calling LLM with tools...\n",
      "12:28:51 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12:28:51 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "12:28:51 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– TRADITIONAL LLM RESPONSE:\n",
      "================================================================================\n",
      "As of the latest data, here is the information about Apple Inc. (AAPL) stock:\n",
      "\n",
      "- **Current Price**: $261.45 USD\n",
      "- **Day's High**: $262.23 USD\n",
      "- **Day's Low**: $255.54 USD\n",
      "- **Volume**: 20,086,962 shares traded\n",
      "- **Market Capitalization**: $3.84 trillion USD\n",
      "\n",
      "If you need more specific information or historical data, feel free to ask!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âŒ Notice: The traditional LLM may ask follow-up questions instead of taking action!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 1: Traditional Reactive LLM\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create traditional agent\n",
    "traditional_agent = create_financial_agent(agent_type=\"traditional\", with_memory=False)\n",
    "\n",
    "# Test query\n",
    "query = \"Tell me about Apple stock\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "# Run agent\n",
    "result = traditional_agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "\n",
    "print(\"\\nðŸ¤– TRADITIONAL LLM RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâŒ Notice: The traditional LLM may ask follow-up questions instead of taking action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300376e8",
   "metadata": {},
   "source": [
    "Test 2: Basic Autonomous Agent (Goal-Oriented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ea6df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:29:37 [INFO] ðŸ“¦ Creating BASIC agent with 4 tools\n",
      "12:29:37 [INFO]    Tools: get_stock_price, get_stock_history, search_financial_news, analyze_sentiment\n",
      "12:29:37 [INFO] âš ï¸  Memory disabled - stateless mode\n",
      "12:29:37 [INFO] âœ… Agent created successfully\n",
      "\n",
      "12:29:37 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "12:29:37 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: Basic Autonomous Agent (Goal-Oriented)\n",
      "================================================================================\n",
      "\n",
      "Query: Tell me about Apple stock\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:29:39 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12:29:39 [INFO]    âœ“ Agent decided to use 3 tool(s)\n",
      "12:29:39 [INFO]       1. get_stock_price\n",
      "12:29:39 [INFO]       2. get_stock_history\n",
      "12:29:39 [INFO]       3. search_financial_news\n",
      "12:29:39 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "12:29:39 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "12:29:41 [INFO]    âœ“ Tools executed successfully\n",
      "12:29:41 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "12:29:41 [INFO]    Calling LLM with tools...\n",
      "12:29:51 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12:29:51 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "12:29:51 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– BASIC AGENT RESPONSE:\n",
      "================================================================================\n",
      "### Apple Inc. (AAPL) Financial Analysis Report\n",
      "\n",
      "#### 1. Current Stock Price and 3-Year Performance Trends\n",
      "- **Current Stock Price**: $261.84 USD\n",
      "- **Market Capitalization**: $3.85 trillion\n",
      "- **Day's Range**: $255.54 - $262.23\n",
      "- **Volume**: 20,146,506 shares traded\n",
      "\n",
      "**3-Year Performance**:\n",
      "- **Start Price (Feb 17, 2023)**: $150.37\n",
      "- **End Price (Feb 17, 2026)**: $261.84\n",
      "- **Return Percentage**: 74.13%\n",
      "- **High**: $288.35\n",
      "- **Low**: $141.85\n",
      "- **Average Volume**: 55,950,742 shares\n",
      "\n",
      "#### 2. Recent Financial News and Market Sentiment\n",
      "Recent news articles indicate a mixed sentiment surrounding Apple:\n",
      "- **AI Investments Scrutiny**: Apple is facing scrutiny over its AI investments and the performance of its news service. Analysts are questioning the company's valuation amidst broader tech market challenges. [Read more here](https://finance.yahoo.com/quote/AAPL/news/).\n",
      "- **Selloff Concerns**: A recent selloff in Apple stock has been deemed \"unwarranted\" by Wedbush analyst Dan Ives, who believes that concerns over delays in AI features are overstated. He maintains an outperform rating with a price target of $350. [Read more here](https://www.investing.com/news/stock-market-news/apple-stock-selloff-unwarrented-wedbushs-ives-says-4508765).\n",
      "- **Legal Challenges**: Apple is also facing potential class action lawsuits related to securities fraud, which could impact investor confidence. [Read more here](https://www.cnn.com/markets/stocks/AAPL).\n",
      "\n",
      "#### 3. Key Risks and Opportunities\n",
      "**Risks**:\n",
      "- **Regulatory Scrutiny**: Ongoing investigations by the FTC regarding potential biases in Apple News could lead to reputational damage and operational changes.\n",
      "- **AI Execution Challenges**: Delays in the rollout of AI features, particularly with Siri, could hinder Apple's competitive edge in the tech market.\n",
      "\n",
      "**Opportunities**:\n",
      "- **AI Monetization Potential**: Analysts estimate that Apple's AI initiatives could add significant value, potentially increasing the stock price by $75 to $100 per share in the coming years.\n",
      "- **Strong Market Position**: With a large installed base of iOS devices, Apple has a solid foundation to leverage its AI capabilities and enhance user engagement.\n",
      "\n",
      "#### 4. Investment Recommendation\n",
      "**Recommendation**: **Buy**\n",
      "- **Supporting Evidence**:\n",
      "  - The stock has shown a robust 74.13% return over the past three years, indicating strong long-term growth potential.\n",
      "  - Despite recent selloff concerns, analysts like Dan Ives believe that the current price does not reflect the true value of Apple's upcoming AI capabilities.\n",
      "  - The company's strong market position and potential for AI monetization present a compelling case for investment.\n",
      "\n",
      "In conclusion, while there are risks associated with regulatory scrutiny and execution challenges, the long-term growth potential and current valuation suggest that Apple Inc. (AAPL) remains a strong buy for investors looking to capitalize on the tech sector's evolution.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âœ… Notice: The agent takes initiative and uses tools to gather data!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 2: Basic Autonomous Agent (Goal-Oriented)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create basic agent\n",
    "basic_agent = create_financial_agent(agent_type=\"basic\", with_memory=False)\n",
    "\n",
    "# Test query\n",
    "query = \"Tell me about Apple stock\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "# Run agent\n",
    "result = basic_agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "\n",
    "print(\"\\nðŸ¤– BASIC AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâœ… Notice: The agent takes initiative and uses tools to gather data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368230d5",
   "metadata": {},
   "source": [
    "Test 3: Full Autonomous Agent (All Constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8551bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:30:32 [INFO] ðŸ“¦ Creating FULL agent with 4 tools\n",
      "12:30:32 [INFO]    Tools: get_stock_price, get_stock_history, search_financial_news, analyze_sentiment\n",
      "12:30:32 [INFO] ðŸ’¾ Enabling conversation memory\n",
      "12:30:32 [INFO] âœ… Agent created successfully\n",
      "\n",
      "12:30:32 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "12:30:32 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 3: Full Autonomous Agent (With All Constraints)\n",
      "================================================================================\n",
      "\n",
      "Query: Provide a comprehensive investment analysis for Microsoft (MSFT) including 3-year performance and AI research activity\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:30:35 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12:30:35 [INFO]    âœ“ Agent decided to use 3 tool(s)\n",
      "12:30:35 [INFO]       1. get_stock_price\n",
      "12:30:35 [INFO]       2. get_stock_history\n",
      "12:30:35 [INFO]       3. search_financial_news\n",
      "12:30:35 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "12:30:35 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "12:30:37 [INFO]    âœ“ Tools executed successfully\n",
      "12:30:37 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "12:30:37 [INFO]    Calling LLM with tools...\n",
      "12:30:53 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "12:30:53 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "12:30:53 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– FULL AGENT RESPONSE:\n",
      "================================================================================\n",
      "### Investment Analysis Report for Microsoft Corporation (MSFT)\n",
      "\n",
      "#### Executive Summary\n",
      "Microsoft Corporation (MSFT) has demonstrated strong financial performance over the past three years, with a notable return of 57.39%. The company is heavily investing in AI research and development, positioning itself as a leader in the AI sector. Recent news indicates a positive market sentiment surrounding Microsoft's AI initiatives, which are expected to drive future growth. \n",
      "\n",
      "#### Financial Metrics\n",
      "- **Current Stock Price**: $397.66 [Source: get_stock_price, 2026-02-17 12:30]\n",
      "- **Market Capitalization**: $2.96 trillion [Source: get_stock_price, 2026-02-17 12:30]\n",
      "- **3-Year Performance**:\n",
      "  - **Start Price (Feb 17, 2023)**: $252.67\n",
      "  - **End Price (Feb 17, 2026)**: $397.66\n",
      "  - **Return Percentage**: 57.39%\n",
      "  - **High**: $553.50\n",
      "  - **Low**: $240.48\n",
      "  - **Average Volume**: 23,603,118 shares [Source: get_stock_history, 2026-02-17]\n",
      "\n",
      "#### Market Sentiment\n",
      "Recent news articles reflect a strong positive sentiment regarding Microsoft's AI initiatives:\n",
      "1. **Microsoft Shapes the AI and ML Landscape in 2024**: Highlights Microsoft's commitment to AI and ML, including educational platforms and global challenges [Source: ProsperSpark, 2024].\n",
      "2. **Understanding AI at Microsoft**: Discusses advancements in AI tools and infrastructure, emphasizing responsible AI practices [Source: Microsoft News, 2024].\n",
      "3. **Microsoft Research 2024**: Showcases innovative AI applications in various fields, including healthcare and environmental science [Source: Microsoft Research, 2024].\n",
      "\n",
      "**Overall Sentiment Score**: High (average sentiment score across articles is approximately 0.999) indicating strong positive sentiment towards Microsoft's AI strategies.\n",
      "\n",
      "#### AI Research Activity\n",
      "Microsoft is actively engaged in several AI projects:\n",
      "- **AI for Good Initiatives**: Focused on leveraging AI to address global challenges.\n",
      "- **Copilot+ PCs**: A new category of Windows PCs designed for enhanced AI experiences.\n",
      "- **AI Model Innovations**: Introduction of new AI models like Phi-3 and advancements in Azure AI tools.\n",
      "- **Scientific Applications**: Development of AI tools for weather forecasting and healthcare, including early detection of diseases [Source: Microsoft Research, 2024].\n",
      "\n",
      "#### Risk Assessment\n",
      "1. **Market Competition**: Intense competition from other tech giants in the AI space could impact market share.\n",
      "2. **Regulatory Risks**: Increasing scrutiny on AI technologies may lead to regulatory challenges.\n",
      "3. **Technological Dependence**: Heavy reliance on cloud infrastructure and AI models may pose risks if not managed effectively.\n",
      "\n",
      "#### Investment Recommendation\n",
      "**Recommendation**: **Buy**\n",
      "- **Confidence Level**: High (80%)\n",
      "- Rationale: Strong financial performance, positive market sentiment, and significant investments in AI position Microsoft favorably for future growth.\n",
      "\n",
      "#### Source Citations\n",
      "- Current stock price and market cap: [Source: get_stock_price, 2026-02-17 12:30]\n",
      "- 3-year performance data: [Source: get_stock_history, 2026-02-17]\n",
      "- News articles and sentiment analysis: [Source: ProsperSpark, Microsoft News, Microsoft Research, 2024]\n",
      "\n",
      "#### Gaps & Limitations\n",
      "- No specific quantitative data on the financial impact of AI initiatives was available.\n",
      "- Future projections are based on current trends and may be subject to change based on market conditions and technological advancements. \n",
      "\n",
      "This comprehensive analysis indicates that Microsoft is well-positioned in the AI sector, making it a strong candidate for investment.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âœ… Notice: The agent provides comprehensive analysis with:\n",
      "   â€¢ Source citations\n",
      "   â€¢ Multiple tool usage\n",
      "   â€¢ Risk assessment\n",
      "   â€¢ Clear recommendation with confidence\n",
      "   â€¢ Data gap acknowledgment\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 3: Full Autonomous Agent (With All Constraints)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create full agent\n",
    "full_agent = create_financial_agent(agent_type=\"full\", with_memory=True)\n",
    "\n",
    "# Test query\n",
    "query = \"Provide a comprehensive investment analysis for Microsoft (MSFT) including 3-year performance and AI research activity\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "# Run agent with memory\n",
    "config = {\"configurable\": {\"thread_id\": \"test_session_1\"}}\n",
    "result = full_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– FULL AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâœ… Notice: The agent provides comprehensive analysis with:\")\n",
    "print(\"   â€¢ Source citations\")\n",
    "print(\"   â€¢ Multiple tool usage\")\n",
    "print(\"   â€¢ Risk assessment\")\n",
    "print(\"   â€¢ Clear recommendation with confidence\")\n",
    "print(\"   â€¢ Data gap acknowledgment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64607520",
   "metadata": {},
   "source": [
    "Simulating Tool Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d60d869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Created failing version of get_stock_price for testing\n",
      "   This will help us observe the agent's error handling behavior\n"
     ]
    }
   ],
   "source": [
    "# Create a modified version of get_stock_price that always fails\n",
    "@tool\n",
    "def get_stock_price_failing(ticker: str) -> Dict:\n",
    "    \"\"\"\n",
    "    [SIMULATED FAILURE] Returns the current stock price - but fails for testing.\n",
    "\n",
    "    Args:\n",
    "        ticker: Stock ticker symbol (e.g., 'AAPL', 'MSFT', 'GOOGL')\n",
    "\n",
    "    Returns:\n",
    "        dict: Error response\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'ticker': ticker.upper(),\n",
    "        'status': 'error',\n",
    "        'error': 'API connection timeout - service temporarily unavailable'\n",
    "    }\n",
    "\n",
    "print(\"âš ï¸  Created failing version of get_stock_price for testing\")\n",
    "print(\"   This will help us observe the agent's error handling behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e74e8",
   "metadata": {},
   "source": [
    "Test Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54bcdee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with failing tool creation function defined\n"
     ]
    }
   ],
   "source": [
    "def create_agent_with_failing_tool():\n",
    "    \"\"\"\n",
    "    Creates an agent where one tool (get_stock_price) always fails.\n",
    "    This tests the agent's reactivity and error handling.\n",
    "    \"\"\"\n",
    "    system_prompt = AGENT_CHARTER_FULL\n",
    "\n",
    "    # Use failing tool instead of working one\n",
    "    tools = [get_stock_price_failing, get_stock_history, search_financial_news, analyze_sentiment]\n",
    "\n",
    "    logger.info(f\"ðŸ“¦ Creating agent with FAILING stock price tool (for testing)\")\n",
    "\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        openai_api_base=os.environ.get(\"OPENAI_API_BASE\")\n",
    "    )\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    def agent_node(state: SimpleAgentState) -> dict:\n",
    "        system_msg = SystemMessage(content=system_prompt)\n",
    "        messages = [system_msg] + list(state[\"messages\"])\n",
    "        response = model_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    def should_continue(state: SimpleAgentState) -> Literal[\"tools\", \"end\"]:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            return \"tools\"\n",
    "        return \"end\"\n",
    "\n",
    "    workflow = StateGraph(SimpleAgentState)\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", \"end\": END})\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "print(\"âœ… Agent with failing tool creation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61bc660",
   "metadata": {},
   "source": [
    "Test Own Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4328084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:18:13 [INFO] ðŸ“¦ Creating TRADITIONAL agent with 4 tools\n",
      "13:18:13 [INFO]    Tools: get_stock_price, get_stock_history, search_financial_news, analyze_sentiment\n",
      "13:18:13 [INFO] ðŸ’¾ Enabling conversation memory\n",
      "13:18:13 [INFO] âœ… Agent created successfully\n",
      "\n",
      "13:18:13 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:18:13 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "YOUR CUSTOM QUERY TEST\n",
      "================================================================================\n",
      "\n",
      "Query: Analyze Tesla stock\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:18:16 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:18:16 [INFO]    âœ“ Agent decided to use 2 tool(s)\n",
      "13:18:16 [INFO]       1. get_stock_price\n",
      "13:18:16 [INFO]       2. get_stock_history\n",
      "13:18:16 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "13:18:16 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "13:18:16 [INFO]    âœ“ Tools executed successfully\n",
      "13:18:16 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:18:16 [INFO]    Calling LLM with tools...\n",
      "13:18:22 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:18:22 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "13:18:22 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AGENT RESPONSE:\n",
      "================================================================================\n",
      "### Tesla Stock Analysis\n",
      "\n",
      "#### Current Stock Information\n",
      "- **Ticker**: TSLA\n",
      "- **Current Price**: $405.84 USD\n",
      "- **Day's High**: $413.72 USD\n",
      "- **Day's Low**: $400.51 USD\n",
      "- **Volume**: 38,076,693 shares\n",
      "- **Market Cap**: $1.52 trillion USD\n",
      "\n",
      "#### Historical Performance (Last 1 Year)\n",
      "- **Start Date**: February 18, 2025\n",
      "- **End Date**: February 17, 2026\n",
      "- **Start Price**: $354.11 USD\n",
      "- **End Price**: $405.84 USD\n",
      "- **Return Percentage**: 14.61%\n",
      "- **High Price**: $498.83 USD\n",
      "- **Low Price**: $214.25 USD\n",
      "- **Average Volume**: 95,724,172 shares\n",
      "- **Data Points**: 251\n",
      "\n",
      "### Summary\n",
      "Tesla's stock has shown a positive return of 14.61% over the past year, with significant fluctuations in price, reaching a high of $498.83 and a low of $214.25. The current trading volume indicates active trading, and the market capitalization reflects its status as a major player in the automotive and technology sectors.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create your agent (choose type: \"traditional\", \"basic\", or \"full\")\n",
    "my_agent = create_financial_agent(\"traditional\", with_memory=True)\n",
    "\n",
    "# Configure memory\n",
    "config = {\"configurable\": {\"thread_id\": \"my_test_session\"}}\n",
    "\n",
    "# Test with your own query\n",
    "# Try these examples or create your own:\n",
    "# - \"Analyze Tesla stock\"\n",
    "# - \"Compare Microsoft and Google AI initiatives\"\n",
    "# - \"What are the risks in investing in NVIDIA?\"\n",
    "# - \"Tell me about Amazon's financial performance\"\n",
    "\n",
    "YOUR_QUERY =  \"Analyze Tesla stock\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"YOUR CUSTOM QUERY TEST\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(f\"Query: {YOUR_QUERY}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "result = my_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=YOUR_QUERY)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763fe96c",
   "metadata": {},
   "source": [
    "# RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffb015af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG libraries imported successfully!\n",
      "   â€¢ RecursiveCharacterTextSplitter - For document chunking\n",
      "   â€¢ PyPDFDirectoryLoader - For loading PDF documents\n",
      "   â€¢ Chroma - Vector database for semantic search\n",
      "   â€¢ OpenAIEmbeddings - For creating embeddings\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for RAG implementation\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "print(\"âœ… RAG libraries imported successfully!\")\n",
    "print(\"   â€¢ RecursiveCharacterTextSplitter - For document chunking\")\n",
    "print(\"   â€¢ PyPDFDirectoryLoader - For loading PDF documents\")\n",
    "print(\"   â€¢ Chroma - Vector database for semantic search\")\n",
    "print(\"   â€¢ OpenAIEmbeddings - For creating embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a4ac4",
   "metadata": {},
   "source": [
    "### Load AI Initiatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3cc24ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/Companies-AI-Initiatives/Companies-AI-Initiatives']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Path of all AI Initiative Documents\n",
    "ai_initiative_pdf_paths = [f\"/content/Companies-AI-Initiatives/{file}\" for file in os.listdir(\"/Users/anshimittal/Downloads/Companies-AI-Initiatives/data/raw_pdfs\")]\n",
    "ai_initiative_pdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c3695fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader \n",
    "\n",
    "loader = PyPDFDirectoryLoader(path = \"/Users/anshimittal/Downloads/Companies-AI-Initiatives/data/raw_pdfs\") # Creating an PDF loader object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc0b61",
   "metadata": {},
   "source": [
    "#### Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42cfed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text splitter configured:\n",
      "   â€¢ Encoding: cl100k_base (OpenAI)\n",
      "   â€¢ Chunk size: 1000 tokens\n",
      "   â€¢ Chunk overlap: 200 tokens\n",
      "   â€¢ Strategy: Recursive character splitting\n",
      "\n",
      "ðŸ“„ Loading and splitting PDF documents...\n",
      "âœ… Documents processed successfully!\n",
      "   â€¢ Total chunks created: 62\n",
      "   â€¢ Average chunk size: ~1000 tokens\n",
      "\n",
      "ðŸ“‹ Sample chunk preview:\n",
      "   Source: /Users/anshimittal/Downloads/Companies-AI-Initiatives/data/raw_pdfs/Companies-AI-Initiatives/IBM.pdf\n",
      "   Content preview: IBM,  a  global  technology  leader,  leverages  artificial  intelligence  to  transform  enterprise  \n",
      "operations\n",
      " \n",
      "and\n",
      " \n",
      "drive\n",
      " \n",
      "innovation\n",
      " \n",
      "across\n",
      " \n",
      "industries.\n",
      " \n",
      "Through\n",
      " \n",
      "platforms\n",
      " \n",
      "like\n",
      " \n",
      "Watso...\n"
     ]
    }
   ],
   "source": [
    "# Chunking the data\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # type: ignore\n",
    "\n",
    "# Define text splitter with tiktoken encoding\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "print(\"âœ… Text splitter configured:\")\n",
    "print(f\"   â€¢ Encoding: cl100k_base (OpenAI)\")\n",
    "print(f\"   â€¢ Chunk size: 1000 tokens\")\n",
    "print(f\"   â€¢ Chunk overlap: 200 tokens\")\n",
    "print(f\"   â€¢ Strategy: Recursive character splitting\")\n",
    "\n",
    "# Load and split documents\n",
    "print(\"\\nðŸ“„ Loading and splitting PDF documents...\")\n",
    "documents = loader.load()\n",
    "ai_initiative_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "print(f\"âœ… Documents processed successfully!\")\n",
    "print(f\"   â€¢ Total chunks created: {len(ai_initiative_chunks)}\")\n",
    "print(f\"   â€¢ Average chunk size: ~1000 tokens\")\n",
    "\n",
    "# Show a sample chunk\n",
    "if ai_initiative_chunks:\n",
    "    print(f\"\\nðŸ“‹ Sample chunk preview:\")\n",
    "    print(f\"   Source: {ai_initiative_chunks[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"   Content preview: {ai_initiative_chunks[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58c06d",
   "metadata": {},
   "source": [
    "#### Create Vector Store with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50fae0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding model initialized: text-embedding-ada-002\n",
      "   â€¢ Embedding dimension: 1536\n",
      "   â€¢ Use case: Semantic similarity search\n",
      "\n",
      "ðŸ”„ Creating vector store (this may take a moment)...\n",
      "   Generating embeddings for all chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:38:41 [INFO] Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "13:38:50 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Vector store created successfully!\n",
      "   â€¢ Collection name: AI_Initiatives\n",
      "   â€¢ Total vectors: 62\n",
      "   â€¢ Database: ChromaDB (in-memory)\n",
      "\n",
      "âœ… Retriever configured:\n",
      "   â€¢ Search type: Similarity\n",
      "   â€¢ Top-k results: 10\n",
      "   â€¢ Ready for queries!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Initialize OpenAI embedding model (text-embedding-ada-002)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "print(\"âœ… Embedding model initialized: text-embedding-ada-002\")\n",
    "print(\"   â€¢ Embedding dimension: 1536\")\n",
    "print(\"   â€¢ Use case: Semantic similarity search\")\n",
    "\n",
    "# Create vector store from documents\n",
    "print(\"\\nðŸ”„ Creating vector store (this may take a moment)...\")\n",
    "print(\"   Generating embeddings for all chunks...\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=ai_initiative_chunks,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"AI_Initiatives\"\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Vector store created successfully!\")\n",
    "print(f\"   â€¢ Collection name: AI_Initiatives\")\n",
    "print(f\"   â€¢ Total vectors: {len(ai_initiative_chunks)}\")\n",
    "print(f\"   â€¢ Database: ChromaDB (in-memory)\")\n",
    "\n",
    "# Create retriever for similarity search which fetches 10 relevant chunks\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "print(f\"\\nâœ… Retriever configured:\")\n",
    "print(f\"   â€¢ Search type: Similarity\")\n",
    "print(f\"   â€¢ Top-k results: 10\")\n",
    "print(f\"   â€¢ Ready for queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf11f1",
   "metadata": {},
   "source": [
    "#### Test RAG Retrieval (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b234040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Test Query: What AI projects is Microsoft working on?\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/flyc_kxs2d554dt8_szth1_40000gn/T/ipykernel_9329/3104663532.py:8: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(test_query)\n",
      "13:39:45 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Retrieved 10 relevant chunks:\n",
      "\n",
      "ðŸ“„ Result 1:\n",
      "   Source: /Users/anshimittal/Downloads/Companies-AI-Initiatives/data/raw_pdfs/Companies-AI-Initiatives/MSFT.pdf\n",
      "   Page: 0\n",
      "   Content: Microsoft,  founded  in  1975,  is  a  global  technology  leader  specializing  in  software,  cloud  \n",
      "computing,\n",
      " \n",
      "AI,\n",
      " \n",
      "and\n",
      " \n",
      "enterprise\n",
      " \n",
      "solutions.\n",
      " \n",
      "The\n",
      " \n",
      "company\n",
      " \n",
      "has\n",
      " \n",
      "aggressively\n",
      " \n",
      "expanded\n",
      " \n",
      "its\n",
      " \n",
      "AI\n",
      " \n",
      "capabilities\n",
      " \n",
      "through\n",
      " \n",
      "initiatives\n",
      " \n",
      "such\n",
      " \n",
      "as\n",
      " \n",
      "Azure\n",
      " \n",
      "AI,\n",
      " \n",
      "OpenAI\n",
      " \n",
      "partnership\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ“„ Result 2:\n",
      "   Source: /Users/anshimittal/Downloads/Companies-AI-Initiatives/data/raw_pdfs/Companies-AI-Initiatives/MSFT.pdf\n",
      "   Page: 3\n",
      "   Content: â—  Enterprise  Enablement :  Provides  organizations  with  tools  to  integrate  AI  into  their  \n",
      "operations,\n",
      " \n",
      "improving\n",
      " \n",
      "efficiency,\n",
      " \n",
      "decision-making,\n",
      " \n",
      "and\n",
      " \n",
      "innovation.\n",
      " â—  Ecosystem  Growth :  Strengthens  the  Microsoft  ecosystem  by  integrating  Foundry  Labs  \n",
      "with\n",
      " \n",
      "Azure,\n",
      " \n",
      "Microsoft...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ“„ Result 3:\n",
      "   Source: /Users/anshimittal/Downloads/Companies-AI-Initiatives/data/raw_pdfs/Companies-AI-Initiatives/MSFT.pdf\n",
      "   Page: 1\n",
      "   Content: growing\n",
      " \n",
      "enterprise\n",
      " \n",
      "and\n",
      " \n",
      "developer\n",
      " \n",
      "demand,\n",
      " \n",
      "with\n",
      " \n",
      "iterative\n",
      " \n",
      "improvements\n",
      " \n",
      "based\n",
      " \n",
      "on\n",
      " \n",
      "feedback\n",
      " \n",
      "and\n",
      " \n",
      "research\n",
      " \n",
      "outcomes.\n",
      " \n",
      "Status  \n",
      "Azure  AI  Foundry  Labs  is  operational  and  actively  evolving .  It  is  now  accessible  to  a  broader  \n",
      "developer\n",
      " \n",
      "community,\n",
      " \n",
      "startups,\n",
      " \n",
      "and\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "test_query = \"What AI projects is Microsoft working on?\"\n",
    "\n",
    "print(f\"ðŸ” Test Query: {test_query}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Retrieve relevant documents\n",
    "relevant_docs = retriever.get_relevant_documents(test_query)\n",
    "\n",
    "print(f\"\\nâœ… Retrieved {len(relevant_docs)} relevant chunks:\\n\")\n",
    "\n",
    "# Display top 3 results\n",
    "for i, doc in enumerate(relevant_docs[:3], 1):\n",
    "    print(f\"ðŸ“„ Result {i}:\")\n",
    "    print(f\"   Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"   Page: {doc.metadata.get('page', 'Unknown')}\")\n",
    "    print(f\"   Content: {doc.page_content[:300]}...\")\n",
    "    print(\"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f3bb6",
   "metadata": {},
   "source": [
    "#### Implement query_private_database tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "639e9aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 5: query_private_database() - Defined\n",
      "   Purpose: Access private analyst reports via RAG\n",
      "   Data Source: ChromaDB vector store\n",
      "   Powered by: OpenAI embeddings + LLM generation\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def query_private_database(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Query the private database of analyst reports and AI initiative documents.\n",
    "\n",
    "    This RAG-powered tool searches through internal company documents about AI initiatives,\n",
    "    research projects, innovation areas, and strategic technology investments. Use this tool\n",
    "    when you need information about:\n",
    "    - Company AI research projects and initiatives\n",
    "    - AI innovation areas and focus\n",
    "    - Technology roadmaps and future plans\n",
    "    - Specific AI project timelines and details\n",
    "\n",
    "    Args:\n",
    "        query: Natural language query about company AI initiatives\n",
    "               (e.g., \"What AI projects is Microsoft working on?\",\n",
    "                      \"NVIDIA's AI research areas\",\n",
    "                      \"Amazon's AI timeline\")\n",
    "\n",
    "    Returns:\n",
    "        str: Detailed answer based on private analyst reports with source citations\n",
    "\n",
    "    Example:\n",
    "        >>> result = query_private_database(\"What are Google's latest AI initiatives?\")\n",
    "        >>> print(result)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # System message for RAG Q&A\n",
    "        qna_system_message = \"\"\"You are an assistant specialized in reviewing AI initiatives of companies and providing accurate answers based on the provided context.\n",
    "\n",
    "User input will include all the context you need to answer their question.\n",
    "This context will always begin with the token: ###Context.\n",
    "The context contains references to specific AI initiatives, projects, or programs of companies relevant to the user's query.\n",
    "\n",
    "User questions will begin with the token: ###Question.\n",
    "\n",
    "Answer only using the context provided. Do not add external information or mention the context in your answer.\n",
    "Always cite which company the information comes from.\n",
    "If the answer cannot be found in the context, respond with \"I don't know - this information is not available in our analyst reports.\"\n",
    "\"\"\"\n",
    "\n",
    "        # User message template\n",
    "        qna_user_message_template = \"\"\"###Context\n",
    "Here are some documents that are relevant to the question mentioned below.\n",
    "{context}\n",
    "\n",
    "###Question\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "        # Retrieve relevant document chunks\n",
    "        relevant_document_chunks = retriever.get_relevant_documents(query)\n",
    "        context_list = [d.page_content for d in relevant_document_chunks]\n",
    "        context_for_query = \". \".join(context_list)\n",
    "\n",
    "        # Build the full prompt\n",
    "        formatted_prompt = f\"\"\"[INST]{qna_system_message}\n",
    "\n",
    "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=query)}\n",
    "                [/INST]\"\"\"\n",
    "\n",
    "        # Query the LLM\n",
    "        model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        response = model.invoke(formatted_prompt)\n",
    "\n",
    "        return response.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error querying private database: {str(e)}\"\n",
    "\n",
    "print(\"âœ… Tool 5: query_private_database() - Defined\")\n",
    "print(\"   Purpose: Access private analyst reports via RAG\")\n",
    "print(\"   Data Source: ChromaDB vector store\")\n",
    "print(\"   Powered by: OpenAI embeddings + LLM generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd7e3d",
   "metadata": {},
   "source": [
    "### Test the RAG Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "635af5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ” Query: What AI projects is Microsoft working on?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:42:15 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:42:21 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Answer:\n",
      "Microsoft is working on several AI projects, including:\n",
      "\n",
      "1. **Azure AI Foundry Labs**: An experimental AI platform designed to accelerate the translation of advanced AI research into real-world applications. It serves as a collaborative hub for developers, startups, enterprises, and Microsoft Research teams, offering early access to cutting-edge AI models, tools, and frameworks.\n",
      "\n",
      "2. **Microsoft 365 Copilot**: An AI-powered productivity assistant embedded across Microsoft 365 applications such as Word, Excel, PowerPoint, Outlook, and Teams. It leverages large language models and Microsoft Graph to provide contextual assistance, automate repetitive tasks, and enhance productivity.\n",
      "\n",
      "These initiatives aim to enhance productivity, streamline workflows, and drive digital transformation while focusing on responsible AI deployment and compliance with ethical standards.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ” Query: What are NVIDIA's AI research areas?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:42:22 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:42:24 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Answer:\n",
      "NVIDIA's AI research areas include deep learning, generative AI, digital twins, and industrial automation. The company leverages its GPUs, specialized chips, and software ecosystems like CUDA and Omniverse to drive innovation across various industries, including healthcare and manufacturing.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ” Query: Tell me about Google's AI initiatives\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:42:25 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:42:33 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Answer:\n",
      "Google has positioned itself as a leader in artificial intelligence (AI) through several key initiatives:\n",
      "\n",
      "1. **Google Brain and DeepMind**: These are foundational research groups that focus on advancing AI technologies and applications.\n",
      "\n",
      "2. **Gemini**: This is Google/DeepMindâ€™s flagship family of multimodal foundation models designed to enhance reasoning, coding, and generative capabilities across text, images, and code. Gemini integrates with various Google products, including Bard, Chrome, and Google Workspace, and comes in multiple tiers optimized for different capabilities.\n",
      "\n",
      "3. **Project Astra**: An advanced AI research prototype aimed at creating a universal AI assistant that integrates seamlessly into daily life. Astra combines multimodal capabilities, processing audio, video, and contextual data to provide real-time assistance across devices, including smartphones and smart glasses.\n",
      "\n",
      "4. **AI Ecosystem**: Googleâ€™s AI ecosystem spans natural language processing, computer vision, speech recognition, and generative AI, enhancing user experiences in products like Google Search, Gmail, Google Assistant, and Google Photos, as well as enterprise solutions via Google Cloudâ€™s Vertex AI.\n",
      "\n",
      "These initiatives emphasize responsible AI development, safety, and ethical deployment, aligning with Google's broader strategy to lead in AI innovation and integrate advanced technologies into everyday user experiences.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the query_private_database tool\n",
    "test_queries = [\n",
    "    \"What AI projects is Microsoft working on?\",\n",
    "    \"What are NVIDIA's AI research areas?\",\n",
    "    \"Tell me about Google's AI initiatives\"\n",
    "]\n",
    "\n",
    "for test_query in test_queries:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ðŸ” Query: {test_query}\\n\")\n",
    "    result = query_private_database.invoke({\"query\": test_query})\n",
    "    print(f\"ðŸ“„ Answer:\\n{result}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335563b8",
   "metadata": {},
   "source": [
    "### Updated Agent Charter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "151890df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated Agent Charter (with RAG tool)\n",
      "   â€¢ Added query_private_database to available tools\n",
      "   â€¢ Added AI Research Activity Check requirements\n",
      "   â€¢ Enhanced quality standards\n"
     ]
    }
   ],
   "source": [
    "AGENT_CHARTER_WITH_RAG = \"\"\"You are an autonomous Financial Research Analyst Agent specializing in AI sector investments.\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "PRIMARY MISSION\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Analyze public companies (especially AI-focused) to generate comprehensive, real-time\n",
    "investment research briefings that provide insights beyond simple data lookup.\n",
    "\n",
    "TARGET OUTPUT:\n",
    "A structured report covering:\n",
    "â€¢ Financial Health: Stock performance, 3-year trends, key metrics\n",
    "â€¢ Market Sentiment: News analysis with sentiment scores\n",
    "â€¢ AI Research Activity: Current AI projects and innovations (using private database)\n",
    "â€¢ Risk Assessment: Key risks and opportunities\n",
    "â€¢ Investment Recommendation: Data-driven rating with confidence level\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "AVAILABLE TOOLS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Stock Data Tools:\n",
    "â€¢ get_stock_price(ticker) - Current price, volume, market cap\n",
    "â€¢ get_stock_history(ticker, period) - Historical data (use '3y' for 3-year analysis)\n",
    "\n",
    "News & Sentiment Tools:\n",
    "â€¢ search_financial_news(query) - Real-time financial news search\n",
    "â€¢ analyze_sentiment(text) - Sentiment analysis with score\n",
    "\n",
    "Private Data Tools (NEW!):\n",
    "â€¢ query_private_database(query) - Query internal analyst reports about AI initiatives\n",
    "  Use this for: AI projects, research areas, innovation timelines, technology roadmaps\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "PROACTIVE BEHAVIOR - Take Initiative\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "âœ“ ALWAYS gather comprehensive data, not just what's explicitly requested\n",
    "âœ“ ALWAYS check 3-year historical performance, not just current price\n",
    "âœ“ ALWAYS analyze recent news sentiment, even if not asked\n",
    "âœ“ ALWAYS query private database for AI research activity\n",
    "âœ“ ALWAYS identify risks proactively, don't wait to be asked\n",
    "âœ“ ALWAYS make a clear recommendation with confidence level\n",
    "\n",
    "âœ— NEVER stop at surface-level data\n",
    "âœ— NEVER provide analysis without supporting evidence\n",
    "âœ— NEVER ignore warning signs in the data\n",
    "âœ— NEVER skip the AI research check\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "REACTIVE BEHAVIOR - Error Handling & Adaptability\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "When Tools Fail:\n",
    "â€¢ If a tool returns an error, IMMEDIATELY try an alternative approach\n",
    "â€¢ If stock data fails, explain the limitation and use news/company info instead\n",
    "â€¢ If news search fails, note this gap and continue with available data\n",
    "â€¢ If private database query fails, note the limitation in your report\n",
    "â€¢ NEVER stop your analysis due to a single tool failure\n",
    "â€¢ Log all errors but maintain momentum toward your goal\n",
    "\n",
    "When Data is Missing:\n",
    "â€¢ If you cannot get 3-year data, use whatever period is available and note it\n",
    "â€¢ If sentiment analysis fails, make qualitative assessment from news titles\n",
    "â€¢ If news is sparse, note this as a finding (low media coverage = risk/opportunity?)\n",
    "â€¢ If AI research data is unavailable, explicitly state this gap\n",
    "â€¢ ALWAYS work with what you have, document what you don't have\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "AUTONOMOUS BEHAVIOR - Independence & Judgment\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Data Gaps & Transparency:\n",
    "â€¢ If you encounter missing data, EXPLICITLY state the gap in your report\n",
    "â€¢ Explain the impact of missing data on your analysis confidence\n",
    "â€¢ NEVER pretend to have data you don't have\n",
    "\n",
    "Source Citation (MANDATORY):\n",
    "â€¢ You MUST cite the source for every factual claim\n",
    "â€¢ Include timestamps for time-sensitive data (stock prices, news)\n",
    "â€¢ For private database queries, cite as [Source: Private Analyst Reports]\n",
    "â€¢ For news articles, you MUST include the article URL as a clickable link\n",
    "â€¢ Format: [Source: tool_name, timestamp] or [Source: Article Title (URL)]\n",
    "\n",
    "Example:\n",
    "âœ“ \"AAPL is trading at $178.45 [Source: get_stock_price, 2024-10-30 13:30]\"\n",
    "âœ“ \"Recent article: 'Apple announces new AI chip' [Source: TechCrunch (https://techcrunch.com/...)]\"\n",
    "âœ“ \"Recent news shows positive sentiment (score: 0.75) [Source: analyze_sentiment]\"\n",
    "âœ“ \"Microsoft is working on Azure AI integration [Source: Private Analyst Reports]\"\n",
    "âœ— \"The stock is doing well\" (no source, no metrics)\n",
    "âœ— \"Recent positive news about Apple\" (no article link or title)\n",
    "\n",
    "IMPORTANT for News Articles:\n",
    "â€¢ When citing news from search_financial_news, ALWAYS extract and include:\n",
    "  - Article title\n",
    "  - Article URL (as a clickable link)\n",
    "â€¢ Format: \"According to '[Article Title]' [Source: Publication (URL)]\"\n",
    "â€¢ Never cite news without providing the actual article link\n",
    "\n",
    "Confidence & Nuance:\n",
    "â€¢ Include confidence levels for predictions: High/Medium/Low\n",
    "â€¢ Acknowledge uncertainty: \"Data suggests...\" vs \"Data confirms...\"\n",
    "â€¢ Note when analysis is limited by data availability\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "AI RESEARCH ACTIVITY CHECK (Section 2.2)\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "For EVERY company analysis, you MUST:\n",
    "1. Query the private database for AI initiatives\n",
    "2. Identify if the company is actively engaged in AI research/innovation\n",
    "3. List the latest 3 areas of AI research or projects (if available)\n",
    "4. Include project timelines and details (if available)\n",
    "\n",
    "Example queries to private database:\n",
    "â€¢ \"What AI projects is [COMPANY] working on?\"\n",
    "â€¢ \"What are [COMPANY]'s AI research areas?\"\n",
    "â€¢ \"[COMPANY] AI initiative timeline\"\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "QUALITY STANDARDS\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Every Report Must Include:\n",
    "1. Executive Summary (2-3 sentences)\n",
    "2. Financial Metrics (with sources and timestamps)\n",
    "3. Sentiment Analysis (with scores and article count)\n",
    "4. AI Research Activity (verified using private database - minimum 3 areas)\n",
    "5. Risk Factors (minimum 2-3 identified)\n",
    "6. Recommendation (Buy/Hold/Sell with confidence %)\n",
    "7. Source Citations (for all claims)\n",
    "8. Gaps & Limitations (what data was unavailable)\n",
    "\n",
    "Remember: You are AUTONOMOUS. Take initiative, handle errors gracefully, and\n",
    "always drive toward your goal of comprehensive investment analysis.\n",
    "Use ALL available tools, especially the private database for AI research insights.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Updated Agent Charter (with RAG tool)\")\n",
    "print(\"   â€¢ Added query_private_database to available tools\")\n",
    "print(\"   â€¢ Added AI Research Activity Check requirements\")\n",
    "print(\"   â€¢ Enhanced quality standards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39490123",
   "metadata": {},
   "source": [
    "### Create Enhanced Agent with RAG Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4098836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced agent creation function defined\n",
      "   â€¢ Includes all 5 tools (stock, news, sentiment, RAG)\n",
      "   â€¢ Uses updated charter with AI research requirements\n"
     ]
    }
   ],
   "source": [
    "def create_enhanced_financial_agent(with_rag: bool = True, with_memory: bool = True):\n",
    "    \"\"\"\n",
    "    Creates an enhanced financial research agent with RAG capabilities.\n",
    "\n",
    "    Args:\n",
    "        with_rag: Whether to include the query_private_database RAG tool\n",
    "        with_memory: Whether to enable conversation memory\n",
    "\n",
    "    Returns:\n",
    "        Compiled LangGraph agent with RAG capabilities\n",
    "    \"\"\"\n",
    "    # Use RAG-enhanced charter\n",
    "    system_prompt = AGENT_CHARTER_WITH_RAG\n",
    "\n",
    "    # Collect all tools (now including RAG tool)\n",
    "    if with_rag:\n",
    "        tools = [\n",
    "            get_stock_price,\n",
    "            get_stock_history,\n",
    "            search_financial_news,\n",
    "            analyze_sentiment,\n",
    "            query_private_database  # NEW!\n",
    "        ]\n",
    "        logger.info(f\"ðŸ“¦ Creating ENHANCED agent with {len(tools)} tools (including RAG)\")\n",
    "    else:\n",
    "        tools = [get_stock_price, get_stock_history, search_financial_news, analyze_sentiment]\n",
    "        logger.info(f\"ðŸ“¦ Creating agent with {len(tools)} tools (no RAG)\")\n",
    "\n",
    "    logger.info(f\"   Tools: {', '.join(t.name for t in tools)}\")\n",
    "\n",
    "    # Initialize model with tools\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    # Define agent node\n",
    "    def agent_node(state: SimpleAgentState) -> dict:\n",
    "        \"\"\"Agent node that calls the LLM with system prompt and current state.\"\"\"\n",
    "        logger.info(\"ðŸ¤– AGENT NODE: Processing request...\")\n",
    "\n",
    "        # Prepare messages with system prompt\n",
    "        system_msg = SystemMessage(content=system_prompt)\n",
    "        messages = [system_msg] + list(state[\"messages\"])\n",
    "\n",
    "        # Invoke model\n",
    "        logger.info(\"   Calling LLM with tools...\")\n",
    "        response = model_with_tools.invoke(messages)\n",
    "\n",
    "        # Log if agent wants to use tools\n",
    "        if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "            logger.info(f\"   âœ“ Agent decided to use {len(response.tool_calls)} tool(s)\")\n",
    "            for i, tool_call in enumerate(response.tool_calls, 1):\n",
    "                logger.info(f\"      {i}. {tool_call['name']}\")\n",
    "        else:\n",
    "            logger.info(\"   âœ“ Agent generated final response (no tools needed)\")\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # Define routing function\n",
    "    def should_continue(state: SimpleAgentState) -> Literal[\"tools\", \"end\"]:\n",
    "        \"\"\"Determines whether to continue to tools or end.\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            logger.info(\"ðŸ”€ ROUTING: Continuing to TOOLS node\")\n",
    "            return \"tools\"\n",
    "\n",
    "\n",
    "        logger.info(\"ðŸ”€ ROUTING: Ending workflow (final response ready)\")\n",
    "        return \"end\"\n",
    "\n",
    "    # Create workflow\n",
    "    workflow = StateGraph(SimpleAgentState)\n",
    "\n",
    "    # Create tool node with logging\n",
    "    original_tool_node = ToolNode(tools)\n",
    "\n",
    "    def tool_node_with_logging(state):\n",
    "        logger.info(\"ðŸ”§ TOOL NODE: Executing tools...\")\n",
    "        result = original_tool_node.invoke(state)\n",
    "        logger.info(f\"   âœ“ Tools executed successfully\")\n",
    "        return result\n",
    "\n",
    "    # Add nodes to graph\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", tool_node_with_logging)\n",
    "\n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "\n",
    "    # Add conditional edge from agent\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add edge from tools back to agent\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # Compile graph\n",
    "    if with_memory:\n",
    "        logger.info(\"ðŸ’¾ Enabling conversation memory\")\n",
    "        memory = MemorySaver()\n",
    "        graph = workflow.compile(checkpointer=memory)\n",
    "    else:\n",
    "        logger.info(\"âš ï¸  Memory disabled - stateless mode\")\n",
    "        graph = workflow.compile()\n",
    "\n",
    "    logger.info(\"âœ… Enhanced agent created successfully\\n\")\n",
    "    return graph\n",
    "\n",
    "print(\"âœ… Enhanced agent creation function defined\")\n",
    "print(\"   â€¢ Includes all 5 tools (stock, news, sentiment, RAG)\")\n",
    "print(\"   â€¢ Uses updated charter with AI research requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21981e4d",
   "metadata": {},
   "source": [
    "### Agent with RAG - AI Research Activity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e923548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:51:34 [INFO] ðŸ“¦ Creating ENHANCED agent with 5 tools (including RAG)\n",
      "13:51:34 [INFO]    Tools: get_stock_price, get_stock_history, search_financial_news, analyze_sentiment, query_private_database\n",
      "13:51:34 [INFO] ðŸ’¾ Enabling conversation memory\n",
      "13:51:34 [INFO] âœ… Enhanced agent created successfully\n",
      "\n",
      "13:51:34 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:51:34 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 5: Enhanced Agent with RAG - AI Research Activity Check\n",
      "================================================================================\n",
      "\n",
      "Query: Provide a comprehensive investment analysis for NVIDIA (NVDA) including their AI research initiatives\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:51:37 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:51:37 [INFO]    âœ“ Agent decided to use 4 tool(s)\n",
      "13:51:37 [INFO]       1. get_stock_price\n",
      "13:51:37 [INFO]       2. get_stock_history\n",
      "13:51:37 [INFO]       3. search_financial_news\n",
      "13:51:37 [INFO]       4. query_private_database\n",
      "13:51:37 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "13:51:37 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "13:51:37 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:51:42 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:51:42 [INFO]    âœ“ Tools executed successfully\n",
      "13:51:42 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:51:42 [INFO]    Calling LLM with tools...\n",
      "13:52:04 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:52:04 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "13:52:04 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– ENHANCED AGENT RESPONSE (with RAG):\n",
      "================================================================================\n",
      "### Comprehensive Investment Analysis for NVIDIA (NVDA)\n",
      "\n",
      "#### Executive Summary\n",
      "NVIDIA Corporation (NVDA) has demonstrated exceptional growth over the past three years, with a staggering return of 767.38%. The company's focus on artificial intelligence (AI) and its innovative projects position it as a leader in the tech sector. Recent advancements in AI technology, particularly in local processing and gaming, further enhance its market potential. Given the strong financial health and positive market sentiment, a **Buy** recommendation is warranted with a high confidence level.\n",
      "\n",
      "---\n",
      "\n",
      "#### 1. Financial Health\n",
      "- **Current Stock Price**: $185.33 [Source: get_stock_price, 2026-02-17 13:51]\n",
      "- **Market Capitalization**: $4.51 trillion\n",
      "- **3-Year Performance**:\n",
      "  - **Start Price (Feb 17, 2023)**: $21.37\n",
      "  - **End Price (Feb 17, 2026)**: $185.33\n",
      "  - **Return Percentage**: 767.38%\n",
      "  - **High**: $212.18\n",
      "  - **Low**: $20.40\n",
      "  - **Average Volume**: 343,576,905 shares [Source: get_stock_history, 2026-02-17]\n",
      "\n",
      "#### 2. Market Sentiment\n",
      "Recent news articles indicate a strong positive sentiment towards NVIDIA's AI initiatives:\n",
      "- **Sentiment Score**: 0.93 (high relevance) [Source: analyze_sentiment]\n",
      "- **Key Articles**:\n",
      "  - **\"Nvidia says these were some of its biggest AI advancements of 2024\"**: Highlights advancements in local AI processing and integration with web browsers. [Source: NVIDIA Blog (https://getcoai.com/news/nvidia-says-these-were-some-of-its-biggest-ai-advancements-of-2024/)]\n",
      "  - **\"7 Major AI Announcements from NVIDIA at SIGGRAPH 2024\"**: Discusses new tools for generative AI and collaborations with Meta. [Source: Dirox (https://dirox.com/post/7-major-ai-announcements-from-nvidia-at-siggraph-2024)]\n",
      "  - **\"2024 AI Predictions | NVIDIA Blog\"**: Focuses on partnerships and advancements in large language models. [Source: NVIDIA Blog (https://blogs.nvidia.com/blog/2024-ai-predictions/)]\n",
      "\n",
      "#### 3. AI Research Activity\n",
      "NVIDIA is actively engaged in several innovative AI projects:\n",
      "1. **Project G-Assist**: An on-device AI assistant for GeForce RTX PCs that utilizes a local small language model for context-aware help and diagnostics.\n",
      "2. **Deep Learning Super Sampling (DLSS) 4**: Enhances real-time AI upscaling and frame generation in gaming, showcasing NVIDIA's capabilities in AI computing.\n",
      "3. **Local AI Processing**: Focus on local deployment of AI models, enhancing privacy and performance compared to cloud solutions. [Source: Private Analyst Reports]\n",
      "\n",
      "#### 4. Risk Assessment\n",
      "- **Market Competition**: Intense competition from other tech giants in AI and gaming sectors could impact market share.\n",
      "- **Regulatory Risks**: Potential regulatory scrutiny on AI technologies and data privacy could pose challenges.\n",
      "- **Supply Chain Issues**: Ongoing global supply chain disruptions may affect production and delivery timelines.\n",
      "\n",
      "#### 5. Investment Recommendation\n",
      "**Recommendation**: **Buy**\n",
      "- **Confidence Level**: High (85%)\n",
      "- The combination of strong financial performance, positive market sentiment, and innovative AI projects supports a bullish outlook on NVIDIA's stock.\n",
      "\n",
      "---\n",
      "\n",
      "#### Source Citations\n",
      "- Stock data and historical performance: [Source: get_stock_price, 2026-02-17] and [Source: get_stock_history, 2026-02-17]\n",
      "- News articles and sentiment analysis: [Source: NVIDIA Blog (https://getcoai.com/news/nvidia-says-these-were-some-of-its-biggest-ai-advancements-of-2024/)], [Source: Dirox (https://dirox.com/post/7-major-ai-announcements-from-nvidia-at-siggraph-2024)], [Source: NVIDIA Blog (https://blogs.nvidia.com/blog/2024-ai-predictions/)]\n",
      "- AI research initiatives: [Source: Private Analyst Reports]\n",
      "\n",
      "#### Gaps & Limitations\n",
      "- No recent earnings report data was available for a more detailed financial analysis.\n",
      "- Limited information on specific timelines for AI projects was found in the private database.\n",
      "\n",
      "This analysis provides a comprehensive overview of NVIDIA's current standing and future potential in the AI sector, making it a compelling investment opportunity.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âœ… Notice: The agent now includes:\n",
      "   â€¢ AI research projects from private analyst reports\n",
      "   â€¢ Specific AI initiative details\n",
      "   â€¢ Integration of financial + AI research data\n",
      "   â€¢ Comprehensive investment recommendation\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 5: Enhanced Agent with RAG - AI Research Activity Check\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create enhanced agent with RAG\n",
    "enhanced_agent = create_enhanced_financial_agent(with_rag=True, with_memory=True)\n",
    "\n",
    "# Test query that requires AI research information\n",
    "query = \"Provide a comprehensive investment analysis for NVIDIA (NVDA) including their AI research initiatives\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "# Run agent with memory\n",
    "config = {\"configurable\": {\"thread_id\": \"enhanced_test_1\"}}\n",
    "result = enhanced_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– ENHANCED AGENT RESPONSE (with RAG):\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâœ… Notice: The agent now includes:\")\n",
    "print(\"   â€¢ AI research projects from private analyst reports\")\n",
    "print(\"   â€¢ Specific AI initiative details\")\n",
    "print(\"   â€¢ Integration of financial + AI research data\")\n",
    "print(\"   â€¢ Comprehensive investment recommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c504de",
   "metadata": {},
   "source": [
    "### Synergistic Tool Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a57165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:52:42 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:52:42 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 6: Synergistic Tool Usage (News + Sentiment + RAG)\n",
      "================================================================================\n",
      "\n",
      "Query: Analyze Microsoft's position in the AI market. Include recent news sentiment and their strategic AI initiatives.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:52:45 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:52:45 [INFO]    âœ“ Agent decided to use 4 tool(s)\n",
      "13:52:45 [INFO]       1. get_stock_price\n",
      "13:52:45 [INFO]       2. get_stock_history\n",
      "13:52:45 [INFO]       3. search_financial_news\n",
      "13:52:45 [INFO]       4. query_private_database\n",
      "13:52:45 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "13:52:45 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "13:52:45 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:52:49 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:52:49 [INFO]    âœ“ Tools executed successfully\n",
      "13:52:49 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:52:49 [INFO]    Calling LLM with tools...\n",
      "13:53:07 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:53:07 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "13:53:07 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AGENT RESPONSE (Synergistic Tool Usage):\n",
      "================================================================================\n",
      "### Microsoft Corporation (MSFT) Investment Analysis\n",
      "\n",
      "#### Executive Summary\n",
      "Microsoft Corporation is strategically positioned as a leader in the AI market, leveraging its extensive resources to drive innovation and enhance productivity across various sectors. Recent developments indicate a strong commitment to ethical AI practices and significant investments in AI technologies, particularly in healthcare and environmental sustainability.\n",
      "\n",
      "---\n",
      "\n",
      "#### Financial Metrics\n",
      "- **Current Stock Price**: $397.44 USD [Source: get_stock_price, 2026-02-17 13:52]\n",
      "- **Market Capitalization**: $2.95 trillion USD\n",
      "- **3-Year Performance**:\n",
      "  - **Start Price (Feb 2023)**: $252.67\n",
      "  - **End Price (Feb 2026)**: $397.44\n",
      "  - **Return**: 57.3%\n",
      "  - **High**: $553.50\n",
      "  - **Low**: $240.48\n",
      "  - **Average Volume**: 23,608,018 shares [Source: get_stock_history, 2026-02-17]\n",
      "\n",
      "---\n",
      "\n",
      "#### Market Sentiment\n",
      "Recent news articles reflect a predominantly positive sentiment towards Microsoft's AI initiatives:\n",
      "1. **\"Microsoft Shapes the AI and ML Landscape in 2024\"** - Highlights Microsoft's commitment to AI and ML investments, focusing on healthcare and environmental sustainability. [Source: ProsperSpark (https://www.prosperspark.com/microsoft-shapes-the-ai-and-ml-landscape-in-2024/)]\n",
      "2. **\"Understanding AI at Microsoft\"** - Discusses advancements in AI tools and responsible AI deployment. [Source: Microsoft News (https://news.microsoft.com/ai/)]\n",
      "3. **\"Unlocking the future: AI and data revolutionize industries at Microsoft Ignite 2024\"** - Emphasizes the transformative potential of AI across various sectors. [Source: Microsoft (https://www.microsoft.com/en-us/industry/blog/general/2024/11/20/unlocking-the-future-ai-and-data-revolutionize-industries-at-microsoft-ignite-2024/)]\n",
      "4. **Sentiment Score**: Average sentiment score across articles is approximately 0.93, indicating strong positive sentiment towards Microsoft's AI strategies.\n",
      "\n",
      "---\n",
      "\n",
      "#### AI Research Activity\n",
      "Microsoft is actively engaged in several key AI projects:\n",
      "1. **Azure AI Foundry Labs**: A collaborative platform for translating advanced AI research into practical applications, providing access to cutting-edge AI models and tools.\n",
      "2. **Microsoft 365 Copilot**: An AI productivity assistant integrated into Microsoft 365 applications, enhancing user efficiency through contextual assistance and automation.\n",
      "3. **GitHub Copilot**: An AI tool designed to assist developers by providing coding support and improving productivity.\n",
      "\n",
      "These initiatives are aimed at driving digital transformation while adhering to ethical AI standards [Source: Private Analyst Reports].\n",
      "\n",
      "---\n",
      "\n",
      "#### Risk Factors\n",
      "1. **Regulatory Scrutiny**: As AI technologies evolve, Microsoft may face increased regulatory scrutiny regarding data privacy and ethical AI practices.\n",
      "2. **Market Competition**: The AI sector is highly competitive, with numerous players vying for market share, which could impact Microsoft's growth potential.\n",
      "3. **Technological Risks**: Rapid advancements in AI technology may require continuous investment and adaptation, posing risks if Microsoft fails to keep pace.\n",
      "\n",
      "---\n",
      "\n",
      "#### Investment Recommendation\n",
      "**Recommendation**: **Buy**\n",
      "- **Confidence Level**: High (85%)\n",
      "- Rationale: Microsoft's strong financial performance, positive market sentiment, and robust AI initiatives position it well for future growth in the AI sector.\n",
      "\n",
      "---\n",
      "\n",
      "#### Source Citations\n",
      "- Stock data: [Source: get_stock_price, 2026-02-17]\n",
      "- Historical performance: [Source: get_stock_history, 2026-02-17]\n",
      "- News articles: \n",
      "  - [ProsperSpark (https://www.prosperspark.com/microsoft-shapes-the-ai-and-ml-landscape-in-2024/)]\n",
      "  - [Microsoft News (https://news.microsoft.com/ai/)]\n",
      "  - [Microsoft (https://www.microsoft.com/en-us/industry/blog/general/2024/11/20/unlocking-the-future-ai-and-data-revolutionize-industries-at-microsoft-ignite-2024/)]\n",
      "- AI initiatives: [Source: Private Analyst Reports]\n",
      "\n",
      "---\n",
      "\n",
      "#### Gaps & Limitations\n",
      "- No recent data on specific regulatory challenges faced by Microsoft in the AI sector.\n",
      "- Limited information on the financial impact of AI initiatives on overall revenue growth.\n",
      "\n",
      "This analysis provides a comprehensive overview of Microsoft's position in the AI market, highlighting its strengths, opportunities, and potential risks.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âœ… The agent demonstrated synergistic tool usage:\n",
      "   1. search_financial_news() - Found recent articles\n",
      "   2. analyze_sentiment() - Analyzed news sentiment\n",
      "   3. query_private_database() - Retrieved AI initiative details\n",
      "   4. get_stock_history() - Got financial performance\n",
      "   5. Synthesized all data into comprehensive report\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 6: Synergistic Tool Usage (News + Sentiment + RAG)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "query = \"Analyze Microsoft's position in the AI market. Include recent news sentiment and their strategic AI initiatives.\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"synergy_test_1\"}}\n",
    "result = enhanced_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– AGENT RESPONSE (Synergistic Tool Usage):\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nâœ… The agent demonstrated synergistic tool usage:\")\n",
    "print(\"   1. search_financial_news() - Found recent articles\")\n",
    "print(\"   2. analyze_sentiment() - Analyzed news sentiment\")\n",
    "print(\"   3. query_private_database() - Retrieved AI initiative details\")\n",
    "print(\"   4. get_stock_history() - Got financial performance\")\n",
    "print(\"   5. Synthesized all data into comprehensive report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5c3db",
   "metadata": {},
   "source": [
    "## Investment Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2080d",
   "metadata": {},
   "source": [
    "### Multi-Company Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6666f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:55:28 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:55:28 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 7: Investment Recommendation System - Multi-Company Ranking\n",
      "================================================================================\n",
      "\n",
      "Query: Multi-company investment ranking\n",
      "\n",
      "Companies: MSFT, GOOGL, NVDA, AMZN, IBM\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:55:36 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:55:36 [INFO]    âœ“ Agent decided to use 20 tool(s)\n",
      "13:55:36 [INFO]       1. get_stock_price\n",
      "13:55:36 [INFO]       2. get_stock_price\n",
      "13:55:36 [INFO]       3. get_stock_price\n",
      "13:55:36 [INFO]       4. get_stock_price\n",
      "13:55:36 [INFO]       5. get_stock_price\n",
      "13:55:36 [INFO]       6. get_stock_history\n",
      "13:55:36 [INFO]       7. get_stock_history\n",
      "13:55:36 [INFO]       8. get_stock_history\n",
      "13:55:36 [INFO]       9. get_stock_history\n",
      "13:55:36 [INFO]       10. get_stock_history\n",
      "13:55:36 [INFO]       11. search_financial_news\n",
      "13:55:36 [INFO]       12. search_financial_news\n",
      "13:55:36 [INFO]       13. search_financial_news\n",
      "13:55:36 [INFO]       14. search_financial_news\n",
      "13:55:36 [INFO]       15. search_financial_news\n",
      "13:55:36 [INFO]       16. query_private_database\n",
      "13:55:36 [INFO]       17. query_private_database\n",
      "13:55:36 [INFO]       18. query_private_database\n",
      "13:55:36 [INFO]       19. query_private_database\n",
      "13:55:36 [INFO]       20. query_private_database\n",
      "13:55:36 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "13:55:36 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "13:55:36 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:55:37 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:55:37 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:55:37 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:55:37 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:55:42 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:55:42 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:55:42 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:55:42 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:55:43 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:55:43 [INFO]    âœ“ Tools executed successfully\n",
      "13:55:43 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:55:43 [INFO]    Calling LLM with tools...\n",
      "13:56:10 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:56:10 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "13:56:10 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– INVESTMENT RANKING REPORT:\n",
      "================================================================================\n",
      "### Comparative Investment Analysis\n",
      "\n",
      "#### 1. Microsoft Corporation (MSFT)\n",
      "- **Current Stock Performance**: $397.40, Market Cap: $2.95 Trillion [Source: get_stock_price, 2026-02-17 13:55]\n",
      "- **3-Year Historical Return**: 57.28% [Source: get_stock_history, 2026-02-17]\n",
      "- **Recent Financial News Sentiment**: Positive sentiment (score: 0.82) with articles highlighting advancements in AI, including the launch of Copilot and Azure AI initiatives [Source: Financial News].\n",
      "- **AI Research Initiatives**:\n",
      "  - **Azure AI Foundry Labs**: A platform for translating AI research into applications.\n",
      "  - **Microsoft 365 Copilot**: AI assistant for productivity tools.\n",
      "  - **GitHub Copilot**: AI-driven coding support tool.\n",
      "- **Risk Factors**: \n",
      "  - Heavy reliance on cloud services.\n",
      "  - Competition from other tech giants in AI.\n",
      "- **Long-Term Growth Outlook**: Strong, driven by continuous innovation in AI and cloud services.\n",
      "\n",
      "#### 2. Alphabet Inc. (GOOGL)\n",
      "- **Current Stock Performance**: $302.60, Market Cap: $3.66 Trillion [Source: get_stock_price, 2026-02-17 13:55]\n",
      "- **3-Year Historical Return**: 223.14% [Source: get_stock_history, 2026-02-17]\n",
      "- **Recent Financial News Sentiment**: Positive sentiment (score: 0.77) with a focus on AI breakthroughs in healthcare and education [Source: Financial News].\n",
      "- **AI Research Initiatives**:\n",
      "  - **Gemini**: Multimodal foundation models for various applications.\n",
      "  - **Project Astra**: Universal AI assistant.\n",
      "  - **Vertex AI**: Unified AI/ML platform for enterprise automation.\n",
      "- **Risk Factors**: \n",
      "  - Regulatory scrutiny over data privacy.\n",
      "  - Dependence on advertising revenue.\n",
      "- **Long-Term Growth Outlook**: Very strong, with significant investments in AI and a diverse product portfolio.\n",
      "\n",
      "#### 3. NVIDIA Corporation (NVDA)\n",
      "- **Current Stock Performance**: $185.65, Market Cap: $4.52 Trillion [Source: get_stock_price, 2026-02-17 13:55]\n",
      "- **3-Year Historical Return**: 768.72% [Source: get_stock_history, 2026-02-17]\n",
      "- **Recent Financial News Sentiment**: Extremely positive sentiment (score: 0.99) with a focus on AI infrastructure and innovations in gaming and enterprise solutions [Source: Financial News].\n",
      "- **AI Research Initiatives**:\n",
      "  - **Project G-Assist**: AI assistant for PCs.\n",
      "  - **Deep Learning Super Sampling (DLSS) 4**: AI-driven image upscaling technology.\n",
      "- **Risk Factors**: \n",
      "  - High valuation relative to earnings.\n",
      "  - Supply chain vulnerabilities.\n",
      "- **Long-Term Growth Outlook**: Exceptional, driven by leadership in AI hardware and software.\n",
      "\n",
      "#### 4. Amazon.com, Inc. (AMZN)\n",
      "- **Current Stock Performance**: $201.23, Market Cap: $2.16 Trillion [Source: get_stock_price, 2026-02-17 13:55]\n",
      "- **3-Year Historical Return**: 107.01% [Source: get_stock_history, 2026-02-17]\n",
      "- **Recent Financial News Sentiment**: Positive sentiment (score: 0.82) with reports on AI investments and innovations in AWS [Source: Financial News].\n",
      "- **AI Research Initiatives**:\n",
      "  - **Amazon SageMaker**: Managed service for ML model deployment.\n",
      "  - **Amazon Bedrock**: Platform for building generative AI applications.\n",
      "- **Risk Factors**: \n",
      "  - High operational costs.\n",
      "  - Intense competition in cloud services.\n",
      "- **Long-Term Growth Outlook**: Strong, with ongoing investments in AI and cloud infrastructure.\n",
      "\n",
      "#### 5. International Business Machines Corporation (IBM)\n",
      "- **Current Stock Performance**: $259.01, Market Cap: $242.11 Billion [Source: get_stock_price, 2026-02-17 13:55]\n",
      "- **3-Year Historical Return**: 112.64% [Source: get_stock_history, 2026-02-17]\n",
      "- **Recent Financial News Sentiment**: Positive sentiment (score: 0.83) focusing on AI training initiatives and partnerships [Source: Financial News].\n",
      "- **AI Research Initiatives**:\n",
      "  - **IBM Granite**: Open-source AI models for enterprises.\n",
      "  - **IBM Watson**: AI platform for business solutions.\n",
      "- **Risk Factors**: \n",
      "  - Slower growth compared to peers.\n",
      "  - Legacy business challenges.\n",
      "- **Long-Term Growth Outlook**: Moderate, with potential in AI but facing competitive pressures.\n",
      "\n",
      "### Ranking Table\n",
      "\n",
      "| Rank | Company | Current Price | 3-Year Return | Sentiment Score | Long-Term Outlook |\n",
      "|------|---------|---------------|----------------|------------------|-------------------|\n",
      "| 1    | NVDA    | $185.65       | 768.72%        | 0.99             | Exceptional        |\n",
      "| 2    | GOOGL   | $302.60       | 223.14%        | 0.77             | Very Strong        |\n",
      "| 3    | MSFT    | $397.40       | 57.28%         | 0.82             | Strong             |\n",
      "| 4    | AMZN    | $201.23       | 107.01%        | 0.82             | Strong             |\n",
      "| 5    | IBM     | $259.01       | 112.64%        | 0.83             | Moderate           |\n",
      "\n",
      "### Final Investment Recommendation\n",
      "\n",
      "**Top Pick**: **NVIDIA Corporation (NVDA)**\n",
      "\n",
      "**Justification**: NVIDIA stands out due to its exceptional 3-year return of 768.72%, strong market sentiment, and leadership in AI hardware and software. The company's ongoing innovations in AI infrastructure and applications position it well for future growth, making it the strongest investment opportunity among the analyzed companies. \n",
      "\n",
      "**Confidence Level**: High.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 7: Investment Recommendation System - Multi-Company Ranking\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Define companies to analyze\n",
    "companies = [\"MSFT\", \"GOOGL\", \"NVDA\", \"AMZN\", \"IBM\"]\n",
    "\n",
    "query = f\"\"\"\n",
    "\n",
    "You are a senior investment analyst. Provide a comparative investment analysis\n",
    "for the following companies.\n",
    "\n",
    "For EACH company:\n",
    "1. Current stock performance\n",
    "2. 3-year historical return\n",
    "3. Recent financial news sentiment\n",
    "4. AI research initiatives and strategic AI positioning\n",
    "5. Risk factors\n",
    "6. Long-term growth outlook\n",
    "\n",
    "Then:\n",
    "- Rank the companies from strongest to weakest investment opportunity\n",
    "- Provide justification for the ranking\n",
    "- Clearly state a top pick and why\n",
    "\n",
    "Companies to analyze: {', '.join(companies)}\n",
    "\n",
    "Deliver the output as:\n",
    "- Individual company summaries\n",
    "- A ranking table\n",
    "- Final investment recommendation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Query: Multi-company investment ranking\\n\")\n",
    "print(f\"Companies: {', '.join(companies)}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"ranking_test_1\"}}\n",
    "result = enhanced_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– INVESTMENT RANKING REPORT:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5be5c",
   "metadata": {},
   "source": [
    "### Custom Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e6a8385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:57:58 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:57:58 [INFO]    Calling LLM with tools...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "YOUR CUSTOM QUERY\n",
      "================================================================================\n",
      "\n",
      "Query: Which company has the most innovative AI research among the analyzed companies? Provide detailed evidence from the private analyst reports.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:58:03 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:03 [INFO]    âœ“ Agent decided to use 5 tool(s)\n",
      "13:58:03 [INFO]       1. query_private_database\n",
      "13:58:03 [INFO]       2. query_private_database\n",
      "13:58:03 [INFO]       3. query_private_database\n",
      "13:58:03 [INFO]       4. query_private_database\n",
      "13:58:03 [INFO]       5. query_private_database\n",
      "13:58:03 [INFO] ðŸ”€ ROUTING: Continuing to TOOLS node\n",
      "13:58:03 [INFO] ðŸ”§ TOOL NODE: Executing tools...\n",
      "13:58:03 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:58:03 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:58:04 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:58:05 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:58:07 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "13:58:08 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:09 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:09 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:11 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:11 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:11 [INFO]    âœ“ Tools executed successfully\n",
      "13:58:11 [INFO] ðŸ¤– AGENT NODE: Processing request...\n",
      "13:58:11 [INFO]    Calling LLM with tools...\n",
      "13:58:28 [INFO] HTTP Request: POST https://aibe.mygreatlearning.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "13:58:28 [INFO]    âœ“ Agent generated final response (no tools needed)\n",
      "13:58:28 [INFO] ðŸ”€ ROUTING: Ending workflow (final response ready)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AGENT RESPONSE:\n",
      "================================================================================\n",
      "### Analysis of AI Research Innovations\n",
      "\n",
      "#### 1. Microsoft Corporation (MSFT)\n",
      "- **AI Projects**:\n",
      "  - **Azure AI Foundry Labs**: An experimental platform that accelerates the translation of advanced AI research into real-world applications, serving as a collaborative hub for developers and researchers.\n",
      "  - **Microsoft 365 Copilot**: An AI-powered assistant integrated into Microsoft 365 applications, enhancing productivity through contextual assistance and automation.\n",
      "- **Innovation Focus**: Microsoft emphasizes responsible AI deployment and compliance with ethical standards, aiming to enhance productivity and streamline workflows.\n",
      "\n",
      "#### 2. Alphabet Inc. (GOOGL)\n",
      "- **AI Projects**:\n",
      "  - **Gemini**: A flagship family of multimodal foundation models designed to enhance reasoning, coding, and generative capabilities across various media types, integrated into Google products.\n",
      "  - **Project Astra**: A prototype for a universal AI assistant that processes audio, video, and contextual data for real-time assistance.\n",
      "  - **Vertex AI**: A unified AI/ML platform with generative media capabilities, aimed at automating enterprise workflows and reducing content creation costs.\n",
      "- **Innovation Focus**: Google is committed to advancing AI technology and integrating it into both consumer and enterprise products, reflecting a strong emphasis on multimodal capabilities.\n",
      "\n",
      "#### 3. NVIDIA Corporation (NVDA)\n",
      "- **AI Projects**:\n",
      "  - **Project G-Assist**: An on-device AI assistant for GeForce RTX PCs that provides context-aware help and diagnostics, enhancing user interaction through natural language.\n",
      "  - **Deep Learning Super Sampling (DLSS) 4**: An AI-driven technology for image upscaling and frame generation, showcasing NVIDIA's capabilities in gaming and real-time applications.\n",
      "- **Innovation Focus**: NVIDIA integrates AI features into consumer products, enhancing user engagement and showcasing its leadership in AI computing.\n",
      "\n",
      "#### 4. Amazon.com, Inc. (AMZN)\n",
      "- **AI Projects**:\n",
      "  - **Amazon SageMaker**: A managed service for building, training, and deploying machine learning models, simplifying the AI development process.\n",
      "  - **Amazon Olympus**: A multimodal AI model for processing text, images, and videos, aimed at enhancing search functionalities.\n",
      "  - **Amazon Bedrock**: A serverless platform for building generative AI applications, democratizing access to advanced AI technologies.\n",
      "- **Innovation Focus**: Amazon focuses on enhancing AI capabilities across various industries, with a strong emphasis on practical applications and accessibility.\n",
      "\n",
      "#### 5. International Business Machines Corporation (IBM)\n",
      "- **AI Projects**:\n",
      "  - **IBM Granite**: A series of open-source AI foundation models designed for enterprise applications, customizable and scalable for various industries.\n",
      "  - **IBM Watson**: A comprehensive suite of AI tools for data analysis and decision-making, evolving to meet complex business challenges.\n",
      "  - **IBM Guardium AI Security**: A solution for securing AI systems, focusing on risk management and governance.\n",
      "- **Innovation Focus**: IBM emphasizes responsible and ethical AI use, providing scalable and customizable solutions for enterprises.\n",
      "\n",
      "### Conclusion: Most Innovative AI Research\n",
      "\n",
      "**Top Innovator**: **Alphabet Inc. (GOOGL)**\n",
      "\n",
      "**Justification**: Google leads in innovative AI research with its Gemini project, which represents a significant advancement in multimodal AI capabilities, integrating reasoning and generative functions across various media. The focus on real-time assistance through Project Astra and the comprehensive capabilities of Vertex AI further solidify Google's position as the most innovative in AI research among the analyzed companies. Their commitment to integrating cutting-edge AI into both consumer and enterprise products showcases a forward-thinking approach that is likely to drive future advancements in the field. \n",
      "\n",
      "**Confidence Level**: High, based on the breadth and depth of AI initiatives and their potential impact on various sectors.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "custom_query = \"Which company has the most innovative AI research among the analyzed companies? Provide detailed evidence from the private analyst reports.\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"YOUR CUSTOM QUERY\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(f\"Query: {custom_query}\\n\")\n",
    "print(\"-\"*80 + \"\\n\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"ranking_test_1\"}}\n",
    "result = enhanced_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=custom_query)]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e13b5",
   "metadata": {},
   "source": [
    "### Summary and Future Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef634e61",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "1. combines difference sources of data from private RAG database to real-time market value and web sentiment\n",
    "2. agent demonstrates autonomous tool routing; thus, decides when to call which tool\n",
    "3. connects financial metrics with strategic AI positioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee72a1",
   "metadata": {},
   "source": [
    "Future Scope\n",
    "1. Could include a composite Investment Score for ranking system\n",
    "2. add risk modeling and monte carlo simulation\n",
    "3. convert into web app with interactive dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
